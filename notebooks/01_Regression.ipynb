{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor flow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Tensor flow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic architecture of a NN\n",
    "\n",
    "* Input layer: same as the number of samples\n",
    "* Hidden layer: Unlimited, minumum 1\n",
    "* Output layer: same as the number of desired outputs (number of classes, if regression, 1)\n",
    "\n",
    "***there are more parameters, they will be covered in more detail latter***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression problem, is simple words, is predicting a number, so lets get going! :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets create some data to fit\n",
    "X = np.array([number for number in range(0, 50)])\n",
    "\n",
    "rand = randint(0, 50) # -> Define a fixed random number that will multiply x\n",
    "Y = np.array([(number * rand) / np.cos(number/rand) for number in X])\n",
    "\n",
    "# Scater\n",
    "plt.scatter(X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But hold ON! If you try to train the model with this, you will encounter problems, bexause tensorflow 2.7+ requires the data to have at least 2 dimensions, in your case the data has 1 dimension mathematicaly speaking, and 0 (\"tensorflowing\" speaking)**\n",
    "\n",
    "***lets fix the data dimensions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "xtr = tf.expand_dims(xtr, axis=-1)\n",
    "xte = tf.expand_dims(xte, axis=-1)\n",
    "\n",
    "ytr = tf.expand_dims(ytr, axis=-1)\n",
    "yte = tf.expand_dims(yte, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is odd, but correct, because the input is a scalar, with has 0 dimensions in tensor flow, and the output as 0 dimensions too**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to build a regression neural network?\n",
    "\n",
    "#### Check bellow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1195.7161 - mae: 1195.7161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fc0a61f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let\"s build a model to fit this problem\n",
    "\n",
    "# Step 1: Create a model: Define the layers (input, hidden, output, and maybe others)\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Sequential([ # -> Sequential API make the layers in the coded order\n",
    "    tf.keras.layers.Dense(1) # -> Just one layer (with 1 neuron)\n",
    "])\n",
    "\n",
    "# Step 2: Compile the model \n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae, # Mean Absolute Error\n",
    "    optimizer=tf.keras.optimizers.SGD(), # Stochastic Gradient Descent\n",
    "    metrics=[\"mae\"] # See how the model is going with this metric\n",
    ")\n",
    "\n",
    "## Define the loss function: The funciton that says how much the model is wrong;\n",
    "## Define the optimizer: The funcitons that says how your model can improve;\n",
    "## Dine eval metrics: The functions that can interpret the performance of your model;\n",
    "\n",
    "# Step 3: Fitting the model: Letting the model find the relations\n",
    "model.fit(xtr, ytr, epochs=50) # -> How have 50 epochs to learn the patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to check model summary?\n",
    "\n",
    "- after fiting, just call model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# Model has 1 layer, which is the dense layer (Its building the input layer behind the scene, summary() doent show it)\n",
    "\n",
    "# it has 2 parameters, wich are the weights and biases, both are trainable for now, because i did not fixed them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary returns:\n",
    "- The output shape\n",
    "- The layers and its types\n",
    "- Trainable parameters: Number of parameters that the model can change while training\n",
    "- Total parameters: Total number of parameters\n",
    "- Non-trainable parameters: Freezed parameters, the model will not change these (normal when ussing pre saved models)\n",
    "\n",
    "What are this parameters?\n",
    "- Bias\n",
    "- Weights\n",
    "\n",
    "Learn more her: https://www.youtube.com/watch?v=7sB052Pz0sQ&ab_channel=AlexanderAmini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making more regression models\n",
    "\n",
    "## Metrics to validate predictions:\n",
    "\n",
    "* MAE\n",
    "* MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make evaluaction functions\n",
    "def mse(yhat, ytrue):\n",
    "    mse_e = tf.keras.losses.MeanSquaredError()\n",
    "    return mse_e(ytrue, yhat)\n",
    "\n",
    "def mae(yhat, ytrue):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()\n",
    "    return mae(ytrue, yhat)\n",
    "\n",
    "def see(yhat, ytrue):\n",
    "    print(f\"Mse: {mse(yhat, ytrue)} | Mae: {mae(yhat, ytrue)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to imporve the firt test model\n",
    "###### Data Scientists rule of thumb: experiment, experiment, experiment\n",
    "\n",
    "* Get more data\n",
    "* Make model larger\n",
    "* Train for longer periods\n",
    "\n",
    "**Lets try some things:**\n",
    "- Model 1: train for longer\n",
    "- Model 2: more epochs at train, and more layer\n",
    "- Model 3: train for 500 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "Training for longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1195.7161 - mae: 1195.7161\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1177.2498 - mae: 1177.2498\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.3679 - mae: 1165.3679\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1157.9121 - mae: 1157.9121\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1140.0149 - mae: 1140.0149\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1123.0496 - mae: 1123.0496\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1105.4407 - mae: 1105.4407\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1090.3107 - mae: 1090.3107\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1078.0863 - mae: 1078.0863\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1059.9420 - mae: 1059.9420\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1050.5829 - mae: 1050.5829\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1040.2543 - mae: 1040.2543\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1021.6632 - mae: 1021.6632\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1005.6870 - mae: 1005.6870\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 997.0180 - mae: 997.0180\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 986.2400 - mae: 986.2400\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 976.2129 - mae: 976.2129\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 959.7241 - mae: 959.7241\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 942.3572 - mae: 942.3572\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 934.7939 - mae: 934.7939\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 921.2932 - mae: 921.2932\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 908.2378 - mae: 908.2378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 901.5795 - mae: 901.5795\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 893.4252 - mae: 893.4252\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 876.0840 - mae: 876.0840\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 861.7178 - mae: 861.7178\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 843.6089 - mae: 843.6089\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 831.7204 - mae: 831.7204\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 814.4788 - mae: 814.4788\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 805.6436 - mae: 805.6436\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 795.7215 - mae: 795.7215\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 791.0927 - mae: 791.0927\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 778.2471 - mae: 778.2471\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 763.7402 - mae: 763.7402\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 750.1713 - mae: 750.1713\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 743.0460 - mae: 743.0460\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 741.2668 - mae: 741.2668\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 740.0448 - mae: 740.0448\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 736.8660 - mae: 736.8660\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 726.4778 - mae: 726.4778\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 719.2236 - mae: 719.2236\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 718.5413 - mae: 718.5413\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 711.2629 - mae: 711.2629\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 705.0186 - mae: 705.0186\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 704.3236 - mae: 704.3236\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 702.7917 - mae: 702.7917\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 701.0508 - mae: 701.0508\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.2601 - mae: 701.2601\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.7204 - mae: 701.7204\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 693.2158 - mae: 693.2158\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.7516 - mae: 685.7516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd5c7670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "model_1.fit(xtr, ytr, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Mse: 626321.6875 | Mae: 402.489501953125\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_1 = model_1.predict(xte)\n",
    "\n",
    "see(y_preds_1, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Training for longer, and incrasing number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1816.0175 - mae: 1816.0175\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1774.4366 - mae: 1774.4366\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1699.6813 - mae: 1699.6813\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1602.2974 - mae: 1602.2974\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1137.5853 - mae: 1137.5853\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 632.1163 - mae: 632.1163\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 952.4985 - mae: 952.4985\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 993.0396 - mae: 993.0396\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 660.8275 - mae: 660.8275\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 688.1006 - mae: 688.1006\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 765.9018 - mae: 765.9018\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 821.7432 - mae: 821.7432\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1297.3496 - mae: 1297.3496\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 819.4653 - mae: 819.4653\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 807.3270 - mae: 807.3270\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1048.9618 - mae: 1048.9618\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1977.7429 - mae: 1977.7429\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.9372 - mae: 595.9372\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 943.3069 - mae: 943.3069\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 988.6705 - mae: 988.6705\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 585.9211 - mae: 585.9211\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 878.8668 - mae: 878.8668\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 886.7725 - mae: 886.7725\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 969.3975 - mae: 969.3975\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1108.2845 - mae: 1108.2845\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.0402 - mae: 578.0402\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 847.5024 - mae: 847.5024\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1010.5807 - mae: 1010.5807\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 737.3079 - mae: 737.3079\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1210.5717 - mae: 1210.5717\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1039.8683 - mae: 1039.8683\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 795.6148 - mae: 795.6148\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.1860 - mae: 587.1860\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1617.1428 - mae: 1617.1428\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2308.2720 - mae: 2308.2720\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3373.3203 - mae: 3373.3203\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 690.9224 - mae: 690.9224\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1833.9457 - mae: 1833.9457\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 645.0174 - mae: 645.0174\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 851.1540 - mae: 851.1540\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 785.9974 - mae: 785.9974\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 981.6179 - mae: 981.6179\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1026.8684 - mae: 1026.8684\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3821 - mae: 589.3821\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.9394 - mae: 589.9394\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 775.0917 - mae: 775.0917\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 869.0668 - mae: 869.0668\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1029.5314 - mae: 1029.5314\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 752.2701 - mae: 752.2701\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1491.5623 - mae: 1491.5623\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2223.4536 - mae: 2223.4536\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 608.1695 - mae: 608.1695\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.0791 - mae: 590.0791\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1409.7762 - mae: 1409.7762\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1867.8629 - mae: 1867.8629\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2562.5256 - mae: 2562.5256\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 780.3823 - mae: 780.3823\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 830.4994 - mae: 830.4994\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1455.4287 - mae: 1455.4287\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.4639 - mae: 599.4639\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 680.0636 - mae: 680.0636\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1498.7717 - mae: 1498.7717\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1118.0316 - mae: 1118.0316\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 881.1511 - mae: 881.1511\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 800.6207 - mae: 800.6207\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 637.9025 - mae: 637.9025\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1204.2213 - mae: 1204.2213\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2059.0020 - mae: 2059.0020\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.2132 - mae: 581.2132\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 895.0942 - mae: 895.0942\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1053.3883 - mae: 1053.3883\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 658.4936 - mae: 658.4936\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.0495 - mae: 597.0495\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1196.0315 - mae: 1196.0315\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 921.7151 - mae: 921.7151\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.1827 - mae: 1165.1827\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 710.2880 - mae: 710.2880\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1566.9760 - mae: 1566.9760\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.8850 - mae: 599.8850\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 842.3273 - mae: 842.3273\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.5808 - mae: 594.5808\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1034.0206 - mae: 1034.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1897.0597 - mae: 1897.0597\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2766.8320 - mae: 2766.8320\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 569.8053 - mae: 569.8053\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.1627 - mae: 599.1627\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 696.6347 - mae: 696.6347\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.0875 - mae: 588.0875\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1183.5697 - mae: 1183.5697\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 860.4949 - mae: 860.4949\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.8687 - mae: 701.8687\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1064.9458 - mae: 1064.9458\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 567.0703 - mae: 567.0703\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.2266 - mae: 597.2266\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 604.3671 - mae: 604.3671\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.1885 - mae: 594.1885\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 763.7223 - mae: 763.7223\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 795.6566 - mae: 795.6566\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1570.6376 - mae: 1570.6376\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2235.1682 - mae: 2235.1682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd5984f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(batch_size=1, input_shape=(1), name=\"InputLayer\"),\n",
    "    tf.keras.layers.Dense(10, name=\"HiddenLayer\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_2.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "model_2.fit(xtr, ytr, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Mse: 292507.375 | Mae: 336.7899169921875\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_2 = model_2.predict(xte)\n",
    "\n",
    "see(y_preds_2, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "Equals to model 1, but with 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1195.7161 - mae: 1195.7161\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1177.2498 - mae: 1177.2498\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.3679 - mae: 1165.3679\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1157.9121 - mae: 1157.9121\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1140.0149 - mae: 1140.0149\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1123.0496 - mae: 1123.0496\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1105.4407 - mae: 1105.4407\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1090.3107 - mae: 1090.3107\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1078.0863 - mae: 1078.0863\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1059.9420 - mae: 1059.9420\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1050.5829 - mae: 1050.5829\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1040.2543 - mae: 1040.2543\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1021.6632 - mae: 1021.6632\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1005.6870 - mae: 1005.6870\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 997.0180 - mae: 997.0180\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 986.2400 - mae: 986.2400\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 976.2129 - mae: 976.2129\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 959.7241 - mae: 959.7241\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 942.3572 - mae: 942.3572\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 934.7939 - mae: 934.7939\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 921.2932 - mae: 921.2932\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 908.2378 - mae: 908.2378\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 901.5795 - mae: 901.5795\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 893.4252 - mae: 893.4252\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 876.0840 - mae: 876.0840\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 861.7178 - mae: 861.7178\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 843.6089 - mae: 843.6089\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 831.7204 - mae: 831.7204\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 814.4788 - mae: 814.4788\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 805.6436 - mae: 805.6436\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 795.7215 - mae: 795.7215\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 791.0927 - mae: 791.0927\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 778.2471 - mae: 778.2471\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 763.7402 - mae: 763.7402\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 750.1713 - mae: 750.1713\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 743.0460 - mae: 743.0460\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 741.2668 - mae: 741.2668\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 740.0448 - mae: 740.0448\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 736.8660 - mae: 736.8660\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 726.4778 - mae: 726.4778\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 719.2236 - mae: 719.2236\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 718.5413 - mae: 718.5413\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 711.2629 - mae: 711.2629\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 705.0186 - mae: 705.0186\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 704.3236 - mae: 704.3236\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 702.7917 - mae: 702.7917\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.0508 - mae: 701.0508\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.2601 - mae: 701.2601\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.7204 - mae: 701.7204\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 693.2158 - mae: 693.2158\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.7516 - mae: 685.7516\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.3978 - mae: 685.3978\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 679.1622 - mae: 679.1622\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 677.8302 - mae: 677.8302\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 672.3395 - mae: 672.3395\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 666.5579 - mae: 666.5579\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 660.0281 - mae: 660.0281\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.3240 - mae: 653.3240\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.7014 - mae: 653.7014\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.2452 - mae: 653.2452\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 647.5685 - mae: 647.5685\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 648.4724 - mae: 648.4724\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 643.2686 - mae: 643.2686\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 643.9183 - mae: 643.9183\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 643.1877 - mae: 643.1877\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 644.2806 - mae: 644.2806\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 644.9874 - mae: 644.9874\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 640.1509 - mae: 640.1509\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 641.3818 - mae: 641.3818\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 637.1581 - mae: 637.1581\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 638.1575 - mae: 638.1575\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 639.2968 - mae: 639.2968\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 634.5330 - mae: 634.5330\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 634.2207 - mae: 634.2207\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 635.0878 - mae: 635.0878\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 634.8641 - mae: 634.8641\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 631.0964 - mae: 631.0964\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 628.0972 - mae: 628.0972\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 629.2130 - mae: 629.2130\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 625.9385 - mae: 625.9385\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 622.4199 - mae: 622.4199\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 622.0364 - mae: 622.0364\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 618.7421 - mae: 618.7421\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 619.1914 - mae: 619.1914\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 619.7120 - mae: 619.7120\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 616.0205 - mae: 616.0205\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 616.3525 - mae: 616.3525\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 613.6409 - mae: 613.6409\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 611.2225 - mae: 611.2225\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 612.1623 - mae: 612.1623\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 612.3223 - mae: 612.3223\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 612.1450 - mae: 612.1450\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 611.9645 - mae: 611.9645\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 611.6392 - mae: 611.6392\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 609.4917 - mae: 609.4917\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 609.8892 - mae: 609.8892\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 610.8859 - mae: 610.8859\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 611.2292 - mae: 611.2292\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 608.6657 - mae: 608.6657\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.1769 - mae: 607.1769\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.2394 - mae: 607.2394\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.7432 - mae: 607.7432\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.8477 - mae: 607.8477\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 606.5282 - mae: 606.5282\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 607.1906 - mae: 607.1906\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.4770 - mae: 607.4770\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.9955 - mae: 605.9955\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 606.5739 - mae: 606.5739\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 607.0131 - mae: 607.0131\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.6935 - mae: 605.6935\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.3561 - mae: 606.3561\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.6450 - mae: 606.6450\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.4824 - mae: 605.4824\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.1029 - mae: 606.1029\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 604.6938 - mae: 604.6938\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 603.1875 - mae: 603.1875\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 603.1071 - mae: 603.1071\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.6080 - mae: 601.6080\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 602.4111 - mae: 602.4111\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.2443 - mae: 601.2443\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.7728 - mae: 601.7728\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 600.2088 - mae: 600.2088\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.0288 - mae: 601.0288\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.4673 - mae: 601.4673\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 599.9957 - mae: 599.9957\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 598.6210 - mae: 598.6210\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.4410 - mae: 599.4410\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.9078 - mae: 599.9078\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.8952 - mae: 599.8952\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 600.6967 - mae: 600.6967\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.3607 - mae: 599.3607\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.6777 - mae: 599.6777\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 600.3575 - mae: 600.3575\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 598.8505 - mae: 598.8505\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 599.5014 - mae: 599.5014\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 598.1240 - mae: 598.1240\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.6633 - mae: 596.6633\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.9503 - mae: 596.9503\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.6086 - mae: 595.6086\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.4751 - mae: 596.4751\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.2469 - mae: 597.2469\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 595.9633 - mae: 595.9633\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.6730 - mae: 596.6730\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.0125 - mae: 595.0125\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 593.6557 - mae: 593.6557\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 594.1972 - mae: 594.1972\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.4837 - mae: 594.4837\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 593.0698 - mae: 593.0698\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 593.6890 - mae: 593.6890\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0744 - mae: 592.0744\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.4909 - mae: 592.4909\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.7144 - mae: 592.7144\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.6370 - mae: 592.6370\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4518 - mae: 591.4518\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 591.5991 - mae: 591.5991\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9513 - mae: 591.9513\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.0866 - mae: 592.0866\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0986 - mae: 592.0986\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.6487 - mae: 590.6487\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.2404 - mae: 591.2404\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9973 - mae: 591.9973\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.4241 - mae: 592.4241\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.8630 - mae: 592.8630\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4553 - mae: 591.4553\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.1456 - mae: 590.1456\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.3095 - mae: 590.3095\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.2989 - mae: 590.2989\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.4938 - mae: 590.4938\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.9594 - mae: 588.9594\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.5629 - mae: 587.5629\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.9161 - mae: 587.9161\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.1127 - mae: 588.1127\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.8228 - mae: 588.8228\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.3043 - mae: 587.3043\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.7715 - mae: 587.7715\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.4604 - mae: 588.4604\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.6821 - mae: 588.6821\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.6033 - mae: 588.6033\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3401 - mae: 589.3401\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.2428 - mae: 589.2428\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.6104 - mae: 589.6104\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.1153 - mae: 590.1153\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.3151 - mae: 590.3151\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.1270 - mae: 591.1270\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4148 - mae: 591.4148\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4802 - mae: 591.4802\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0092 - mae: 592.0092\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.5182 - mae: 590.5182\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.8817 - mae: 590.8817\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.3186 - mae: 591.3186\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9951 - mae: 591.9951\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.8550 - mae: 591.8550\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.5441 - mae: 590.5441\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.7087 - mae: 590.7087\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.4279 - mae: 591.4279\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.6808 - mae: 591.6808\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.3016 - mae: 592.3016\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.9266 - mae: 590.9266\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.7641 - mae: 589.7641\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.3864 - mae: 590.3864\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.2023 - mae: 589.2023\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3804 - mae: 589.3804\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.7336 - mae: 589.7336\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.8677 - mae: 589.8677\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.3649 - mae: 588.3649\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.9877 - mae: 586.9877\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.0283 - mae: 587.0283\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.9909 - mae: 586.9909\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.3352 - mae: 587.3352\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.9550 - mae: 587.9550\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4496 - mae: 586.4496\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4003 - mae: 586.4003\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.4794 - mae: 585.4794\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 585.9949 - mae: 585.9949\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.0495 - mae: 586.0495\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.3655 - mae: 586.3655\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.3515 - mae: 586.3515\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4989 - mae: 586.4989\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.8454 - mae: 586.8454\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.7955 - mae: 586.7955\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.5361 - mae: 585.5361\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.7674 - mae: 585.7674\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.0890 - mae: 586.0890\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.2244 - mae: 586.2244\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.2988 - mae: 586.2988\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.0687 - mae: 587.0687\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.7626 - mae: 587.7626\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.1389 - mae: 588.1389\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.7886 - mae: 588.7886\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.2233 - mae: 587.2233\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.9383 - mae: 585.9383\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.6765 - mae: 586.6765\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.3227 - mae: 587.3227\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.2280 - mae: 587.2280\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.6081 - mae: 587.6081\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.3876 - mae: 586.3876\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.3907 - mae: 585.3907\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.9464 - mae: 584.9464\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.4423 - mae: 584.4423\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.9842 - mae: 583.9842\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5390 - mae: 583.5390\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5752 - mae: 583.5752\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1242 - mae: 583.1242\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4301 - mae: 583.4301\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.6171 - mae: 583.6171\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.8696 - mae: 583.8696\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.0178 - mae: 584.0178\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.1710 - mae: 584.1710\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.3937 - mae: 584.3937\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.5561 - mae: 584.5561\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.5609 - mae: 584.5609\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.0867 - mae: 584.0867\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.3979 - mae: 584.3979\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.6523 - mae: 584.6523\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.8256 - mae: 584.8256\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.8395 - mae: 584.8395\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.3938 - mae: 584.3938\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.9346 - mae: 583.9346\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.1290 - mae: 584.1290\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.6597 - mae: 583.6597\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2039 - mae: 583.2039\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7008 - mae: 582.7008\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7557 - mae: 582.7557\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.0690 - mae: 583.0690\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2142 - mae: 583.2142\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4628 - mae: 583.4628\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.9454 - mae: 582.9454\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.1551 - mae: 583.1551\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4257 - mae: 583.4257\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5399 - mae: 583.5399\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.7999 - mae: 583.7999\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2510 - mae: 583.2510\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7483 - mae: 582.7483\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.2554 - mae: 582.2554\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.8232 - mae: 581.8232\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0750 - mae: 582.0750\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2162 - mae: 582.2162\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.4127 - mae: 582.4127\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.4841 - mae: 582.4841\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.9490 - mae: 581.9490\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2248 - mae: 582.2248\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.4114 - mae: 582.4114\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.4919 - mae: 582.4919\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.9847 - mae: 581.9847\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.1620 - mae: 582.1620\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2626 - mae: 582.2626\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.3130 - mae: 582.3130\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.5682 - mae: 582.5682\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.5511 - mae: 582.5511\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5898 - mae: 582.5898\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.6740 - mae: 582.6740\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.8244 - mae: 582.8244\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1351 - mae: 583.1351\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2140 - mae: 583.2140\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7871 - mae: 582.7871\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.0973 - mae: 583.0973\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5933 - mae: 582.5933\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.6193 - mae: 582.6193\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.8243 - mae: 582.8243\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.3929 - mae: 582.3929\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.6532 - mae: 582.6532\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7490 - mae: 582.7490\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.0261 - mae: 583.0261\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.0205 - mae: 583.0205\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1463 - mae: 583.1463\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2468 - mae: 583.2468\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7894 - mae: 582.7894\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.3339 - mae: 582.3339\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5852 - mae: 582.5852\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0219 - mae: 582.0219\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0164 - mae: 582.0164\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1373 - mae: 582.1373\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1292 - mae: 582.1292\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.6201 - mae: 581.6201\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.9284 - mae: 581.9284\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1237 - mae: 582.1237\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1399 - mae: 582.1399\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.1765 - mae: 582.1765\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.7180 - mae: 581.7180\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.7115 - mae: 581.7115\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.1503 - mae: 581.1503\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.6573 - mae: 580.6573\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.2112 - mae: 580.2112\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.2269 - mae: 580.2269\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 579.7603 - mae: 579.7603\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 579.2328 - mae: 579.2328\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.7835 - mae: 578.7835\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.9604 - mae: 578.9604\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.4328 - mae: 578.4328\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.4529 - mae: 578.4529\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.7214 - mae: 578.7214\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.7625 - mae: 578.7625\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1999 - mae: 578.1999\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7474 - mae: 577.7474\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.8856 - mae: 577.8856\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1741 - mae: 578.1741\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.3800 - mae: 578.3800\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.9214 - mae: 577.9214\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1312 - mae: 578.1312\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.5746 - mae: 577.5746\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7109 - mae: 577.7109\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.8140 - mae: 577.8140\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.8892 - mae: 577.8892\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.0350 - mae: 578.0350\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.1135 - mae: 578.1135\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1143 - mae: 578.1143\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.3344 - mae: 578.3344\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7866 - mae: 577.7866\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.0532 - mae: 578.0532\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.2394 - mae: 578.2394\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7468 - mae: 577.7468\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.9627 - mae: 577.9627\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.5062 - mae: 577.5062\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.0149 - mae: 577.0149\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.5225 - mae: 576.5225\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.5485 - mae: 576.5485\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.7583 - mae: 576.7583\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2043 - mae: 576.2043\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.3799 - mae: 576.3799\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.8873 - mae: 575.8873\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.4307 - mae: 575.4307\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.9482 - mae: 574.9482\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.1525 - mae: 575.1525\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.3397 - mae: 575.3397\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.4316 - mae: 575.4316\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7809 - mae: 575.7809\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.8145 - mae: 575.8145\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.1207 - mae: 576.1207\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.3036 - mae: 576.3036\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.6118 - mae: 576.6118\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.1654 - mae: 576.1654\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7224 - mae: 575.7224\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.9795 - mae: 575.9795\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.9841 - mae: 575.9841\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.0093 - mae: 576.0093\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2048 - mae: 576.2048\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7493 - mae: 575.7493\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0063 - mae: 576.0063\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.2017 - mae: 576.2017\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7471 - mae: 575.7471\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0159 - mae: 576.0159\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.2354 - mae: 576.2354\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.6900 - mae: 575.6900\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.8125 - mae: 575.8125\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.3401 - mae: 575.3401\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5196 - mae: 575.5196\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.6477 - mae: 575.6477\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7897 - mae: 575.7897\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7904 - mae: 575.7904\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0071 - mae: 576.0071\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5286 - mae: 575.5286\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5991 - mae: 575.5991\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.0967 - mae: 575.0967\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5966 - mae: 574.5966\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.7010 - mae: 574.7010\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2533 - mae: 574.2533\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.6765 - mae: 574.6765\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5615 - mae: 574.5615\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9966 - mae: 574.9966\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9592 - mae: 574.9592\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5099 - mae: 575.5099\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.0167 - mae: 576.0167\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7744 - mae: 575.7744\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2180 - mae: 576.2180\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.9397 - mae: 575.9397\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5928 - mae: 575.5928\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.5457 - mae: 575.5457\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.2789 - mae: 575.2789\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.0942 - mae: 575.0942\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7821 - mae: 574.7821\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.2740 - mae: 575.2740\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7286 - mae: 575.7286\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.3907 - mae: 575.3907\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.1941 - mae: 575.1941\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9971 - mae: 574.9971\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7311 - mae: 574.7311\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6040 - mae: 574.6040\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4524 - mae: 574.4524\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9716 - mae: 574.9716\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5383 - mae: 574.5383\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3650 - mae: 574.3650\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1693 - mae: 574.1693\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2520 - mae: 574.2520\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5074 - mae: 574.5074\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6917 - mae: 574.6917\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.8866 - mae: 574.8866\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4290 - mae: 574.4290\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4460 - mae: 574.4460\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2506 - mae: 574.2506\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1930 - mae: 574.1930\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3293 - mae: 574.3293\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3347 - mae: 574.3347\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3177 - mae: 574.3177\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2595 - mae: 574.2595\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2125 - mae: 574.2125\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4901 - mae: 574.4901\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6849 - mae: 574.6849\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.6893 - mae: 574.6893\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2422 - mae: 574.2422\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.4521 - mae: 574.4521\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2275 - mae: 574.2275\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2036 - mae: 574.2036\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2944 - mae: 574.2944\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.5218 - mae: 574.5218\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7402 - mae: 574.7402\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2195 - mae: 574.2195\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3665 - mae: 574.3665\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2777 - mae: 574.2777\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1354 - mae: 574.1354\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.3242 - mae: 574.3242\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4412 - mae: 574.4412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd706c70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "# Make model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model_3.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model_3.fit(xtr, ytr, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Mse: 306998.09375 | Mae: 406.56842041015625\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_3 = model_3.predict(xte)\n",
    "\n",
    "see(y_preds_3, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=306998.1>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_preds_3, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model1</td>\n",
       "      <td>402.489502</td>\n",
       "      <td>626321.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model2</td>\n",
       "      <td>336.789917</td>\n",
       "      <td>292507.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model3</td>\n",
       "      <td>406.568420</td>\n",
       "      <td>306998.09375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model         mae           mse\n",
       "0  Model1  402.489502  626321.68750\n",
       "1  Model2  336.789917  292507.37500\n",
       "2  Model3  406.568420  306998.09375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = [\n",
    "    [\"Model1\", mae(y_preds_1, yte).numpy(), mse(y_preds_1, yte).numpy()],\n",
    "    [\"Model2\", mae(y_preds_2, yte).numpy(), mse(y_preds_2, yte).numpy()],\n",
    "    [\"Model3\", mae(y_preds_3, yte).numpy(), mse(y_preds_3, yte).numpy()]\n",
    "]\n",
    "\n",
    "model_results = pd.DataFrame(models_results, columns=[\"model\", \"mae\", \"mse\"])\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer (Dense)         (1, 10)                   20        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 1)                    11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 2 was the better\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your main goal is to minimize the time between training sessions, because the more ou try different things and works in cicle, the more you discover the things that dont work, and the more you aproximate the better possible model, remember the machine learning people motto: experiment, experiment, experiment!\n",
    "\n",
    "This is the reason why you compare models! You try simple models first, see the best, try variatons of the best, take the best, and move on!\n",
    "\n",
    "Now we are gonna stop testing because this is a course, but in real life, you wold take model 2 and move on with the exprimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking your experiments (This is a very, very, good practice)\n",
    "\n",
    "We have tools for this:\n",
    "\n",
    "* TensorBoard\n",
    "* Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving your models\n",
    "\n",
    "2 Ways:\n",
    "\n",
    "* SavedModel format\n",
    "* HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) InputLayer with unsupported characters which will be renamed to inputlayer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model with SavedModel\n",
    "model_2.save(\"model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with hdf5\n",
    "model_2.save(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer (Dense)         (1, 10)                   20        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 1)                    11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load from savedModel\n",
    "l_model = tf.keras.models.load_model(\"model2\")\n",
    "l_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer (Dense)         (1, 10)                   20        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 1)                    11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load from h5 five format\n",
    "h_model = tf.keras.models.load_model(\"model2.h5\")\n",
    "h_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of all topics at this module\n",
    "\n",
    "## Lets do all the steps learned at this notebook again, with a more \"real\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 0s 932us/step - loss: 6.4569 - mae: 6.4569\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.5992 - mae: 1.5992\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5997 - mae: 0.5997\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3951 - mae: 0.3951\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3184 - mae: 0.3184\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2918 - mae: 0.2918\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2745 - mae: 0.2745\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2613 - mae: 0.2613\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2604 - mae: 0.2604\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2569 - mae: 0.2569\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2617 - mae: 0.2617\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2553 - mae: 0.2553\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2609 - mae: 0.2609\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2575 - mae: 0.2575\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2572 - mae: 0.2572\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2579 - mae: 0.2579\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2590 - mae: 0.2590\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2621 - mae: 0.2621\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2563 - mae: 0.2563\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2533 - mae: 0.2533\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2546 - mae: 0.2546\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2586 - mae: 0.2586\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2599 - mae: 0.2599\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2557 - mae: 0.2557\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2611 - mae: 0.2611\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2525 - mae: 0.2525\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2540 - mae: 0.2540\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2646 - mae: 0.2646\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2511 - mae: 0.2511\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2646 - mae: 0.2646\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2547 - mae: 0.2547\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2754 - mae: 0.2754\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2607 - mae: 0.2607\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2620 - mae: 0.2620\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2606 - mae: 0.2606\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2547 - mae: 0.2547\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2556 - mae: 0.2556\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2659 - mae: 0.2659\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2542 - mae: 0.2542\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2575 - mae: 0.2575\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2526 - mae: 0.2526\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2539 - mae: 0.2539\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2537 - mae: 0.2537\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2503 - mae: 0.2503\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2571 - mae: 0.2571\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2598 - mae: 0.2598\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2574 - mae: 0.2574\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2605 - mae: 0.2605\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2675 - mae: 0.2675\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2626 - mae: 0.2626\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2559 - mae: 0.2559\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2664 - mae: 0.2664\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2586 - mae: 0.2586\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2641 - mae: 0.2641\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2629 - mae: 0.2629\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2612 - mae: 0.2612\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2633 - mae: 0.2633\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2683 - mae: 0.2683\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2618 - mae: 0.2618\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2580 - mae: 0.2580\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2550 - mae: 0.2550\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2497 - mae: 0.2497\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2631 - mae: 0.2631\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2569 - mae: 0.2569\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2562 - mae: 0.2562\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2586 - mae: 0.2586\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2578 - mae: 0.2578\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2543 - mae: 0.2543\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2517 - mae: 0.2517\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2556 - mae: 0.2556\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2564 - mae: 0.2564\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2530 - mae: 0.2530\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2574 - mae: 0.2574\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2670 - mae: 0.2670\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2591 - mae: 0.2591\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2581 - mae: 0.2581\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2604 - mae: 0.2604\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2781 - mae: 0.2781\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2701 - mae: 0.2701\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2572 - mae: 0.2572\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2605 - mae: 0.2605\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2532 - mae: 0.2532\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2585 - mae: 0.2585\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2578 - mae: 0.2578\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2547 - mae: 0.2547\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2548 - mae: 0.2548\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2593 - mae: 0.2593\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2696 - mae: 0.2696\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2541 - mae: 0.2541\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2527 - mae: 0.2527\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2522 - mae: 0.2522\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2533 - mae: 0.2533\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2566 - mae: 0.2566\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.2530 - mae: 0.2530\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2526 - mae: 0.2526\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2547 - mae: 0.2547\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2557 - mae: 0.2557\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2583 - mae: 0.2583\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2532 - mae: 0.2532\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2585 - mae: 0.2585\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2594 - mae: 0.2594\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2589 - mae: 0.2589\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.2548 - mae: 0.2548\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2633 - mae: 0.2633\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.2615 - mae: 0.2615\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2685 - mae: 0.2685\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2677 - mae: 0.2677\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2540 - mae: 0.2540\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.2589 - mae: 0.2589\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2546 - mae: 0.2546\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.2537 - mae: 0.2537\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2527 - mae: 0.2527\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.2539 - mae: 0.2539\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2542 - mae: 0.2542\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2640 - mae: 0.2640\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2607 - mae: 0.2607\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2532 - mae: 0.2532\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2595 - mae: 0.2595\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2593 - mae: 0.2593\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2580 - mae: 0.2580\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2784 - mae: 0.2784\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2672 - mae: 0.2672\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2539 - mae: 0.2539\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2720 - mae: 0.2720\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.2580 - mae: 0.2580\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2553 - mae: 0.2553\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2572 - mae: 0.2572\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2544 - mae: 0.2544\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2515 - mae: 0.2515\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2589 - mae: 0.2589\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2620 - mae: 0.2620\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2583 - mae: 0.2583\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2562 - mae: 0.2562\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2671 - mae: 0.2671\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2631 - mae: 0.2631\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2553 - mae: 0.2553\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2613 - mae: 0.2613\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2647 - mae: 0.2647\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2541 - mae: 0.2541\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2582 - mae: 0.2582\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2676 - mae: 0.2676\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2526 - mae: 0.2526\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2522 - mae: 0.2522\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.2539 - mae: 0.2539\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2527 - mae: 0.2527\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.2510 - mae: 0.2510\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.2662 - mae: 0.2662\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2638 - mae: 0.2638\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2639 - mae: 0.2639\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2596 - mae: 0.2596\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2555 - mae: 0.2555\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2551 - mae: 0.2551\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2598 - mae: 0.2598\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2557 - mae: 0.2557\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2534 - mae: 0.2534\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2583 - mae: 0.2583\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2565 - mae: 0.2565\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2570 - mae: 0.2570\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2631 - mae: 0.2631\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.2570 - mae: 0.2570\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.2520 - mae: 0.2520\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2548 - mae: 0.2548\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.2603 - mae: 0.2603\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.2531 - mae: 0.2531\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2629 - mae: 0.2629\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2578 - mae: 0.2578\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2566 - mae: 0.2566\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2551 - mae: 0.2551\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2712 - mae: 0.2712\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2596 - mae: 0.2596\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2633 - mae: 0.2633\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2542 - mae: 0.2542\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2596 - mae: 0.2596\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2571 - mae: 0.2571\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2621 - mae: 0.2621\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.2592 - mae: 0.2592\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.2521 - mae: 0.2521\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2552 - mae: 0.2552\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2629 - mae: 0.2629\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2524 - mae: 0.2524\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2528 - mae: 0.2528\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2511 - mae: 0.2511\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2573 - mae: 0.2573\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2587 - mae: 0.2587\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2590 - mae: 0.2590\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2611 - mae: 0.2611\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.2557 - mae: 0.2557\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2532 - mae: 0.2532\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2514 - mae: 0.2514\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2519 - mae: 0.2519\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2549 - mae: 0.2549\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2662 - mae: 0.2662\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2602 - mae: 0.2602\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2651 - mae: 0.2651\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2627 - mae: 0.2627\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2614 - mae: 0.2614\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2558 - mae: 0.2558\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2666 - mae: 0.2666\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2658 - mae: 0.2658\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2556 - mae: 0.2556\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2829 - mae: 0.2829\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2730 - mae: 0.2730\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2670 - mae: 0.2670\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2534 - mae: 0.2534\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2573 - mae: 0.2573\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2587 - mae: 0.2587\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2557 - mae: 0.2557\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2571 - mae: 0.2571\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2671 - mae: 0.2671\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2619 - mae: 0.2619\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2655 - mae: 0.2655\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2694 - mae: 0.2694\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2604 - mae: 0.2604\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2554 - mae: 0.2554\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2556 - mae: 0.2556\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2666 - mae: 0.2666\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2538 - mae: 0.2538\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2552 - mae: 0.2552\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2584 - mae: 0.2584\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2576 - mae: 0.2576\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.2584 - mae: 0.2584\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2669 - mae: 0.2669\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2588 - mae: 0.2588\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2597 - mae: 0.2597\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2549 - mae: 0.2549\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2587 - mae: 0.2587\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2510 - mae: 0.2510\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2581 - mae: 0.2581\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2643 - mae: 0.2643\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2569 - mae: 0.2569\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2552 - mae: 0.2552\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2579 - mae: 0.2579\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2554 - mae: 0.2554\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2539 - mae: 0.2539\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2625 - mae: 0.2625\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2525 - mae: 0.2525\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2518 - mae: 0.2518\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2574 - mae: 0.2574\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2566 - mae: 0.2566\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2530 - mae: 0.2530\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2581 - mae: 0.2581\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2537 - mae: 0.2537\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2590 - mae: 0.2590\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.2662 - mae: 0.2662\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2605 - mae: 0.2605\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.2539 - mae: 0.2539\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2559 - mae: 0.2559\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2556 - mae: 0.2556\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2533 - mae: 0.2533\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2518 - mae: 0.2518\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2607 - mae: 0.2607\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2542 - mae: 0.2542\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2583 - mae: 0.2583\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2542 - mae: 0.2542\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2519 - mae: 0.2519\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2548 - mae: 0.2548\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.2585 - mae: 0.2585\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2573 - mae: 0.2573\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2571 - mae: 0.2571\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2571 - mae: 0.2571\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2576 - mae: 0.2576\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2533 - mae: 0.2533\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2543 - mae: 0.2543\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2599 - mae: 0.2599\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2596 - mae: 0.2596\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2539 - mae: 0.2539\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2553 - mae: 0.2553\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2663 - mae: 0.2663\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2633 - mae: 0.2633\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2568 - mae: 0.2568\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2593 - mae: 0.2593\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.2550 - mae: 0.2550\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2575 - mae: 0.2575\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2583 - mae: 0.2583\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2583 - mae: 0.2583\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2708 - mae: 0.2708\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2636 - mae: 0.2636\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2543 - mae: 0.2543\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2525 - mae: 0.2525\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2575 - mae: 0.2575\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2512 - mae: 0.2512\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2550 - mae: 0.2550\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2565 - mae: 0.2565\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2523 - mae: 0.2523\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2586 - mae: 0.2586\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2717 - mae: 0.2717\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.2556 - mae: 0.2556\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2553 - mae: 0.2553\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.2556 - mae: 0.2556\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2513 - mae: 0.2513\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2558 - mae: 0.2558\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2548 - mae: 0.2548\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2656 - mae: 0.2656\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2566 - mae: 0.2566\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2557 - mae: 0.2557\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2532 - mae: 0.2532\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2582 - mae: 0.2582\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2602 - mae: 0.2602\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2534 - mae: 0.2534\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2537 - mae: 0.2537\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2569 - mae: 0.2569\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2520 - mae: 0.2520\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2551 - mae: 0.2551\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2563 - mae: 0.2563\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2592 - mae: 0.2592\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2602 - mae: 0.2602\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2554 - mae: 0.2554\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2596 - mae: 0.2596\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2643 - mae: 0.2643\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2586 - mae: 0.2586\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2519 - mae: 0.2519\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2559 - mae: 0.2559\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2528 - mae: 0.2528\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2604 - mae: 0.2604\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2590 - mae: 0.2590\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2613 - mae: 0.2613\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2586 - mae: 0.2586\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2550 - mae: 0.2550\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2522 - mae: 0.2522\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2597 - mae: 0.2597\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2547 - mae: 0.2547\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2610 - mae: 0.2610\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2579 - mae: 0.2579\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2513 - mae: 0.2513\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2541 - mae: 0.2541\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2571 - mae: 0.2571\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2544 - mae: 0.2544\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2631 - mae: 0.2631\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2638 - mae: 0.2638\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2573 - mae: 0.2573\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2570 - mae: 0.2570\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2560 - mae: 0.2560\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2549 - mae: 0.2549\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2571 - mae: 0.2571\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2563 - mae: 0.2563\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2569 - mae: 0.2569\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2559 - mae: 0.2559\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2502 - mae: 0.2502\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2560 - mae: 0.2560\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2568 - mae: 0.2568\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2555 - mae: 0.2555\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2542 - mae: 0.2542\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2632 - mae: 0.2632\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2539 - mae: 0.2539\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2570 - mae: 0.2570\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2574 - mae: 0.2574\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2609 - mae: 0.2609\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2610 - mae: 0.2610\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2546 - mae: 0.2546\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2510 - mae: 0.2510\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2520 - mae: 0.2520\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2561 - mae: 0.2561\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2574 - mae: 0.2574\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2572 - mae: 0.2572\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2527 - mae: 0.2527\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2534 - mae: 0.2534\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2569 - mae: 0.2569\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2553 - mae: 0.2553\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2574 - mae: 0.2574\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2553 - mae: 0.2553\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2560 - mae: 0.2560\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2620 - mae: 0.2620\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2635 - mae: 0.2635\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2559 - mae: 0.2559\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2519 - mae: 0.2519\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2554 - mae: 0.2554\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2541 - mae: 0.2541\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2572 - mae: 0.2572\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2590 - mae: 0.2590\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2578 - mae: 0.2578\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2513 - mae: 0.2513\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2603 - mae: 0.2603\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2605 - mae: 0.2605\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2595 - mae: 0.2595\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2533 - mae: 0.2533\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.2537 - mae: 0.2537\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2606 - mae: 0.2606\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2570 - mae: 0.2570\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2534 - mae: 0.2534\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2602 - mae: 0.2602\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2531 - mae: 0.2531\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2527 - mae: 0.2527\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2526 - mae: 0.2526\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2530 - mae: 0.2530\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2567 - mae: 0.2567\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2543 - mae: 0.2543\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2582 - mae: 0.2582\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2559 - mae: 0.2559\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2579 - mae: 0.2579\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2521 - mae: 0.2521\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2550 - mae: 0.2550\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2564 - mae: 0.2564\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2555 - mae: 0.2555\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2575 - mae: 0.2575\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2517 - mae: 0.2517\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2586 - mae: 0.2586\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2533 - mae: 0.2533\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2553 - mae: 0.2553\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2531 - mae: 0.2531\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2549 - mae: 0.2549\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2542 - mae: 0.2542\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2557 - mae: 0.2557\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2554 - mae: 0.2554\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2554 - mae: 0.2554\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2570 - mae: 0.2570\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2636 - mae: 0.2636\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.2714 - mae: 0.2714\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2544 - mae: 0.2544\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.2517 - mae: 0.2517\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2603 - mae: 0.2603\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2514 - mae: 0.2514\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2611 - mae: 0.2611\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2643 - mae: 0.2643\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2526 - mae: 0.2526\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.2598 - mae: 0.2598\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2568 - mae: 0.2568\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2519 - mae: 0.2519\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2542 - mae: 0.2542\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2528 - mae: 0.2528\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2692 - mae: 0.2692\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2550 - mae: 0.2550\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2559 - mae: 0.2559\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2551 - mae: 0.2551\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.2538 - mae: 0.2538\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2549 - mae: 0.2549\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2585 - mae: 0.2585\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2528 - mae: 0.2528\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2555 - mae: 0.2555\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2523 - mae: 0.2523\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2589 - mae: 0.2589\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2521 - mae: 0.2521\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2606 - mae: 0.2606\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2600 - mae: 0.2600\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2554 - mae: 0.2554\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2514 - mae: 0.2514\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2631 - mae: 0.2631\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2570 - mae: 0.2570\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2566 - mae: 0.2566\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2577 - mae: 0.2577\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2569 - mae: 0.2569\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2527 - mae: 0.2527\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2555 - mae: 0.2555\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2523 - mae: 0.2523\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2593 - mae: 0.2593\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2555 - mae: 0.2555\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2561 - mae: 0.2561\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2566 - mae: 0.2566\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2578 - mae: 0.2578\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2598 - mae: 0.2598\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2546 - mae: 0.2546\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2570 - mae: 0.2570\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2673 - mae: 0.2673\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2536 - mae: 0.2536\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2571 - mae: 0.2571\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2752 - mae: 0.2752\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2716 - mae: 0.2716\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2578 - mae: 0.2578\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2769 - mae: 0.2769\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2574 - mae: 0.2574\n"
     ]
    }
   ],
   "source": [
    "# Lets import the necessary modules\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "\n",
    "# Aplly log transofrm at y\n",
    "df[\"charges\"] = df[\"charges\"].apply(lambda x: np.log(x))\n",
    "\n",
    "# X and Y\n",
    "X = df[[col for col in df.columns if col != \"charges\"]]\n",
    "Y = df[\"charges\"]\n",
    "\n",
    "# Make column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Separate train ans test data\n",
    "xtr, xte, ytr, yte = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "# Apply scaler and encoding with column transformer\n",
    "xtr = ct.fit_transform(xtr)\n",
    "xte = ct.transform(xte)\n",
    "\n",
    "# Make model\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "NN = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(11)),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile\n",
    "NN.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Adam(), metrics=[\"mae\"])\n",
    "\n",
    "# Fit\n",
    "history = NN.fit(xtr, ytr, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2610 - mae: 0.2610\n",
      "Model performance:\n",
      " MAE: 0.2610050439834595\n"
     ]
    }
   ],
   "source": [
    "# Plot predictions against real value\n",
    "print(f\"Model performance:\\n MAE: {NN.evaluate(xte, yte)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 998us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model predictions\n",
    "yhat = pd.Series(NN.predict(xte).ravel())\n",
    "\n",
    "sns.scatterplot(x=yte.apply(lambda x: np.e**x), y=yhat.apply(lambda x: np.e**x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning history\n",
    "pd.DataFrame(history.history).plot();\n",
    "\n",
    "# --> The loss (y axis) decreases with more epochs, but it gets kinda stuck around epoch 300, consider early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.02535169073515"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.000000000000014"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e**4.02535169073515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baf1db779f0cdc1ce48b1fe9bcd8ead02e6c1caf4dfdb394510f91c1920b3eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
