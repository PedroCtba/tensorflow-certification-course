{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor flow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Tensor flow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic architecture of a NN\n",
    "\n",
    "* Input layer: same as the number of samples\n",
    "* Hidden layer: Unlimited, minumum 1\n",
    "* Output layer: same as the number of desired outputs (number of classes, if regression, 1)\n",
    "\n",
    "***there are more parameters, they will be covered in more detail latter***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression problem, is simple words, is predicting a number, so lets get going! :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets create some data to fit\n",
    "X = np.array([number for number in range(0, 50)])\n",
    "\n",
    "rand = randint(0, 50) # -> Define a fixed random number that will multiply x\n",
    "Y = np.array([(number * rand) / np.cos(number/rand) for number in X])\n",
    "\n",
    "# Scater\n",
    "plt.scatter(X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But hold ON! If you try to train the model with this, you will encounter problems, bexause tensorflow 2.7+ requires the data to have at least 2 dimensions, in your case the data has 1 dimension mathematicaly speaking, and 0 (\"tensorflowing\" speaking)**\n",
    "\n",
    "***lets fix the data dimensions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "xtr = tf.expand_dims(xtr, axis=-1)\n",
    "xte = tf.expand_dims(xte, axis=-1)\n",
    "\n",
    "ytr = tf.expand_dims(ytr, axis=-1)\n",
    "yte = tf.expand_dims(yte, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is odd, but correct, because the input is a scalar, with has 0 dimensions in tensor flow, and the output as 0 dimensions too**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to build a regression neural network?\n",
    "\n",
    "#### Check bellow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1195.7161 - mae: 1195.7161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fc0a61f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let\"s build a model to fit this problem\n",
    "\n",
    "# Step 1: Create a model: Define the layers (input, hidden, output, and maybe others)\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Sequential([ # -> Sequential API make the layers in the coded order\n",
    "    tf.keras.layers.Dense(1) # -> Just one layer (with 1 neuron)\n",
    "])\n",
    "\n",
    "# Step 2: Compile the model \n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae, # Mean Absolute Error\n",
    "    optimizer=tf.keras.optimizers.SGD(), # Stochastic Gradient Descent\n",
    "    metrics=[\"mae\"] # See how the model is going with this metric\n",
    ")\n",
    "\n",
    "## Define the loss function: The funciton that says how much the model is wrong;\n",
    "## Define the optimizer: The funcitons that says how your model can improve;\n",
    "## Dine eval metrics: The functions that can interpret the performance of your model;\n",
    "\n",
    "# Step 3: Fitting the model: Letting the model find the relations\n",
    "model.fit(xtr, ytr, epochs=50) # -> How have 50 epochs to learn the patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to check model summary?\n",
    "\n",
    "- after fiting, just call model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# Model has 1 layer, which is the dense layer (Its building the input layer behind the scene, summary() doent show it)\n",
    "\n",
    "# it has 2 parameters, wich are the weights and biases, both are trainable for now, because i did not fixed them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary returns:\n",
    "- The output shape\n",
    "- The layers and its types\n",
    "- Trainable parameters: Number of parameters that the model can change while training\n",
    "- Total parameters: Total number of parameters\n",
    "- Non-trainable parameters: Freezed parameters, the model will not change these (normal when ussing pre saved models)\n",
    "\n",
    "What are this parameters?\n",
    "- Bias\n",
    "- Weights\n",
    "\n",
    "Learn more her: https://www.youtube.com/watch?v=7sB052Pz0sQ&ab_channel=AlexanderAmini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making more regression models\n",
    "\n",
    "## Metrics to validate predictions:\n",
    "\n",
    "* MAE\n",
    "* MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make evaluaction functions\n",
    "def mse(yhat, ytrue):\n",
    "    mse_e = tf.keras.losses.MeanSquaredError()\n",
    "    return mse_e(ytrue, yhat)\n",
    "\n",
    "def mae(yhat, ytrue):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()\n",
    "    return mae(ytrue, yhat)\n",
    "\n",
    "def see(yhat, ytrue):\n",
    "    print(f\"Mse: {mse(yhat, ytrue)} | Mae: {mae(yhat, ytrue)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to imporve the firt test model\n",
    "###### Data Scientists rule of thumb: experiment, experiment, experiment\n",
    "\n",
    "* Get more data\n",
    "* Make model larger\n",
    "* Train for longer periods\n",
    "\n",
    "**Lets try some things:**\n",
    "- Model 1: train for longer\n",
    "- Model 2: more epochs at train, and more layer\n",
    "- Model 3: train for 500 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "Training for longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1195.7161 - mae: 1195.7161\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1177.2498 - mae: 1177.2498\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.3679 - mae: 1165.3679\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1157.9121 - mae: 1157.9121\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1140.0149 - mae: 1140.0149\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1123.0496 - mae: 1123.0496\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1105.4407 - mae: 1105.4407\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1090.3107 - mae: 1090.3107\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1078.0863 - mae: 1078.0863\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1059.9420 - mae: 1059.9420\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1050.5829 - mae: 1050.5829\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1040.2543 - mae: 1040.2543\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1021.6632 - mae: 1021.6632\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1005.6870 - mae: 1005.6870\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 997.0180 - mae: 997.0180\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 986.2400 - mae: 986.2400\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 976.2129 - mae: 976.2129\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 959.7241 - mae: 959.7241\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 942.3572 - mae: 942.3572\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 934.7939 - mae: 934.7939\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 921.2932 - mae: 921.2932\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 908.2378 - mae: 908.2378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 901.5795 - mae: 901.5795\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 893.4252 - mae: 893.4252\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 876.0840 - mae: 876.0840\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 861.7178 - mae: 861.7178\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 843.6089 - mae: 843.6089\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 831.7204 - mae: 831.7204\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 814.4788 - mae: 814.4788\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 805.6436 - mae: 805.6436\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 795.7215 - mae: 795.7215\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 791.0927 - mae: 791.0927\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 778.2471 - mae: 778.2471\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 763.7402 - mae: 763.7402\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 750.1713 - mae: 750.1713\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 743.0460 - mae: 743.0460\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 741.2668 - mae: 741.2668\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 740.0448 - mae: 740.0448\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 736.8660 - mae: 736.8660\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 726.4778 - mae: 726.4778\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 719.2236 - mae: 719.2236\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 718.5413 - mae: 718.5413\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 711.2629 - mae: 711.2629\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 705.0186 - mae: 705.0186\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 704.3236 - mae: 704.3236\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 702.7917 - mae: 702.7917\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 701.0508 - mae: 701.0508\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.2601 - mae: 701.2601\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.7204 - mae: 701.7204\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 693.2158 - mae: 693.2158\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.7516 - mae: 685.7516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd5c7670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "model_1.fit(xtr, ytr, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Mse: 626321.6875 | Mae: 402.489501953125\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_1 = model_1.predict(xte)\n",
    "\n",
    "see(y_preds_1, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Training for longer, and incrasing number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1816.0175 - mae: 1816.0175\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1774.4366 - mae: 1774.4366\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1699.6813 - mae: 1699.6813\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1602.2974 - mae: 1602.2974\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1137.5853 - mae: 1137.5853\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 632.1163 - mae: 632.1163\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 952.4985 - mae: 952.4985\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 993.0396 - mae: 993.0396\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 660.8275 - mae: 660.8275\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 688.1006 - mae: 688.1006\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 765.9018 - mae: 765.9018\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 821.7432 - mae: 821.7432\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1297.3496 - mae: 1297.3496\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 819.4653 - mae: 819.4653\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 807.3270 - mae: 807.3270\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1048.9618 - mae: 1048.9618\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1977.7429 - mae: 1977.7429\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.9372 - mae: 595.9372\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 943.3069 - mae: 943.3069\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 988.6705 - mae: 988.6705\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 585.9211 - mae: 585.9211\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 878.8668 - mae: 878.8668\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 886.7725 - mae: 886.7725\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 969.3975 - mae: 969.3975\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1108.2845 - mae: 1108.2845\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.0402 - mae: 578.0402\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 847.5024 - mae: 847.5024\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1010.5807 - mae: 1010.5807\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 737.3079 - mae: 737.3079\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1210.5717 - mae: 1210.5717\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1039.8683 - mae: 1039.8683\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 795.6148 - mae: 795.6148\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.1860 - mae: 587.1860\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1617.1428 - mae: 1617.1428\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2308.2720 - mae: 2308.2720\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3373.3203 - mae: 3373.3203\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 690.9224 - mae: 690.9224\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1833.9457 - mae: 1833.9457\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 645.0174 - mae: 645.0174\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 851.1540 - mae: 851.1540\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 785.9974 - mae: 785.9974\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 981.6179 - mae: 981.6179\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1026.8684 - mae: 1026.8684\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3821 - mae: 589.3821\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.9394 - mae: 589.9394\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 775.0917 - mae: 775.0917\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 869.0668 - mae: 869.0668\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1029.5314 - mae: 1029.5314\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 752.2701 - mae: 752.2701\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1491.5623 - mae: 1491.5623\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2223.4536 - mae: 2223.4536\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 608.1695 - mae: 608.1695\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.0791 - mae: 590.0791\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1409.7762 - mae: 1409.7762\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1867.8629 - mae: 1867.8629\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2562.5256 - mae: 2562.5256\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 780.3823 - mae: 780.3823\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 830.4994 - mae: 830.4994\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1455.4287 - mae: 1455.4287\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.4639 - mae: 599.4639\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 680.0636 - mae: 680.0636\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1498.7717 - mae: 1498.7717\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1118.0316 - mae: 1118.0316\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 881.1511 - mae: 881.1511\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 800.6207 - mae: 800.6207\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 637.9025 - mae: 637.9025\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1204.2213 - mae: 1204.2213\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2059.0020 - mae: 2059.0020\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.2132 - mae: 581.2132\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 895.0942 - mae: 895.0942\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1053.3883 - mae: 1053.3883\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 658.4936 - mae: 658.4936\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.0495 - mae: 597.0495\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1196.0315 - mae: 1196.0315\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 921.7151 - mae: 921.7151\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.1827 - mae: 1165.1827\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 710.2880 - mae: 710.2880\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1566.9760 - mae: 1566.9760\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.8850 - mae: 599.8850\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 842.3273 - mae: 842.3273\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.5808 - mae: 594.5808\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1034.0206 - mae: 1034.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1897.0597 - mae: 1897.0597\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2766.8320 - mae: 2766.8320\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 569.8053 - mae: 569.8053\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.1627 - mae: 599.1627\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 696.6347 - mae: 696.6347\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.0875 - mae: 588.0875\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1183.5697 - mae: 1183.5697\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 860.4949 - mae: 860.4949\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.8687 - mae: 701.8687\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1064.9458 - mae: 1064.9458\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 567.0703 - mae: 567.0703\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.2266 - mae: 597.2266\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 604.3671 - mae: 604.3671\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.1885 - mae: 594.1885\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 763.7223 - mae: 763.7223\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 795.6566 - mae: 795.6566\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1570.6376 - mae: 1570.6376\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2235.1682 - mae: 2235.1682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd5984f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(batch_size=1, input_shape=(1), name=\"InputLayer\"),\n",
    "    tf.keras.layers.Dense(10, name=\"HiddenLayer\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_2.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "model_2.fit(xtr, ytr, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Mse: 292507.375 | Mae: 336.7899169921875\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_2 = model_2.predict(xte)\n",
    "\n",
    "see(y_preds_2, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "Equals to model 1, but with 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1195.7161 - mae: 1195.7161\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1177.2498 - mae: 1177.2498\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.3679 - mae: 1165.3679\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1157.9121 - mae: 1157.9121\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1140.0149 - mae: 1140.0149\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1123.0496 - mae: 1123.0496\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1105.4407 - mae: 1105.4407\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1090.3107 - mae: 1090.3107\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1078.0863 - mae: 1078.0863\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1059.9420 - mae: 1059.9420\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1050.5829 - mae: 1050.5829\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1040.2543 - mae: 1040.2543\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1021.6632 - mae: 1021.6632\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1005.6870 - mae: 1005.6870\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 997.0180 - mae: 997.0180\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 986.2400 - mae: 986.2400\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 976.2129 - mae: 976.2129\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 959.7241 - mae: 959.7241\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 942.3572 - mae: 942.3572\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 934.7939 - mae: 934.7939\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 921.2932 - mae: 921.2932\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 908.2378 - mae: 908.2378\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 901.5795 - mae: 901.5795\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 893.4252 - mae: 893.4252\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 876.0840 - mae: 876.0840\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 861.7178 - mae: 861.7178\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 843.6089 - mae: 843.6089\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 831.7204 - mae: 831.7204\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 814.4788 - mae: 814.4788\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 805.6436 - mae: 805.6436\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 795.7215 - mae: 795.7215\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 791.0927 - mae: 791.0927\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 778.2471 - mae: 778.2471\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 763.7402 - mae: 763.7402\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 750.1713 - mae: 750.1713\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 743.0460 - mae: 743.0460\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 741.2668 - mae: 741.2668\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 740.0448 - mae: 740.0448\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 736.8660 - mae: 736.8660\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 726.4778 - mae: 726.4778\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 719.2236 - mae: 719.2236\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 718.5413 - mae: 718.5413\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 711.2629 - mae: 711.2629\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 705.0186 - mae: 705.0186\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 704.3236 - mae: 704.3236\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 702.7917 - mae: 702.7917\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.0508 - mae: 701.0508\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.2601 - mae: 701.2601\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.7204 - mae: 701.7204\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 693.2158 - mae: 693.2158\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.7516 - mae: 685.7516\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.3978 - mae: 685.3978\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 679.1622 - mae: 679.1622\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 677.8302 - mae: 677.8302\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 672.3395 - mae: 672.3395\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 666.5579 - mae: 666.5579\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 660.0281 - mae: 660.0281\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.3240 - mae: 653.3240\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.7014 - mae: 653.7014\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.2452 - mae: 653.2452\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 647.5685 - mae: 647.5685\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 648.4724 - mae: 648.4724\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 643.2686 - mae: 643.2686\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 643.9183 - mae: 643.9183\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 643.1877 - mae: 643.1877\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 644.2806 - mae: 644.2806\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 644.9874 - mae: 644.9874\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 640.1509 - mae: 640.1509\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 641.3818 - mae: 641.3818\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 637.1581 - mae: 637.1581\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 638.1575 - mae: 638.1575\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 639.2968 - mae: 639.2968\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 634.5330 - mae: 634.5330\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 634.2207 - mae: 634.2207\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 635.0878 - mae: 635.0878\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 634.8641 - mae: 634.8641\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 631.0964 - mae: 631.0964\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 628.0972 - mae: 628.0972\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 629.2130 - mae: 629.2130\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 625.9385 - mae: 625.9385\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 622.4199 - mae: 622.4199\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 622.0364 - mae: 622.0364\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 618.7421 - mae: 618.7421\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 619.1914 - mae: 619.1914\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 619.7120 - mae: 619.7120\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 616.0205 - mae: 616.0205\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 616.3525 - mae: 616.3525\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 613.6409 - mae: 613.6409\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 611.2225 - mae: 611.2225\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 612.1623 - mae: 612.1623\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 612.3223 - mae: 612.3223\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 612.1450 - mae: 612.1450\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 611.9645 - mae: 611.9645\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 611.6392 - mae: 611.6392\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 609.4917 - mae: 609.4917\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 609.8892 - mae: 609.8892\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 610.8859 - mae: 610.8859\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 611.2292 - mae: 611.2292\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 608.6657 - mae: 608.6657\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.1769 - mae: 607.1769\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.2394 - mae: 607.2394\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.7432 - mae: 607.7432\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.8477 - mae: 607.8477\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 606.5282 - mae: 606.5282\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 607.1906 - mae: 607.1906\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.4770 - mae: 607.4770\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.9955 - mae: 605.9955\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 606.5739 - mae: 606.5739\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 607.0131 - mae: 607.0131\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.6935 - mae: 605.6935\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.3561 - mae: 606.3561\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.6450 - mae: 606.6450\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.4824 - mae: 605.4824\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.1029 - mae: 606.1029\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 604.6938 - mae: 604.6938\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 603.1875 - mae: 603.1875\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 603.1071 - mae: 603.1071\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.6080 - mae: 601.6080\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 602.4111 - mae: 602.4111\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.2443 - mae: 601.2443\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.7728 - mae: 601.7728\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 600.2088 - mae: 600.2088\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.0288 - mae: 601.0288\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.4673 - mae: 601.4673\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 599.9957 - mae: 599.9957\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 598.6210 - mae: 598.6210\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.4410 - mae: 599.4410\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.9078 - mae: 599.9078\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.8952 - mae: 599.8952\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 600.6967 - mae: 600.6967\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.3607 - mae: 599.3607\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.6777 - mae: 599.6777\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 600.3575 - mae: 600.3575\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 598.8505 - mae: 598.8505\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 599.5014 - mae: 599.5014\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 598.1240 - mae: 598.1240\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.6633 - mae: 596.6633\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.9503 - mae: 596.9503\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.6086 - mae: 595.6086\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.4751 - mae: 596.4751\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.2469 - mae: 597.2469\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 595.9633 - mae: 595.9633\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.6730 - mae: 596.6730\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.0125 - mae: 595.0125\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 593.6557 - mae: 593.6557\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 594.1972 - mae: 594.1972\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.4837 - mae: 594.4837\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 593.0698 - mae: 593.0698\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 593.6890 - mae: 593.6890\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0744 - mae: 592.0744\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.4909 - mae: 592.4909\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.7144 - mae: 592.7144\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.6370 - mae: 592.6370\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4518 - mae: 591.4518\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 591.5991 - mae: 591.5991\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9513 - mae: 591.9513\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.0866 - mae: 592.0866\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0986 - mae: 592.0986\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.6487 - mae: 590.6487\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.2404 - mae: 591.2404\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9973 - mae: 591.9973\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.4241 - mae: 592.4241\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.8630 - mae: 592.8630\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4553 - mae: 591.4553\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.1456 - mae: 590.1456\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.3095 - mae: 590.3095\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.2989 - mae: 590.2989\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.4938 - mae: 590.4938\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.9594 - mae: 588.9594\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.5629 - mae: 587.5629\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.9161 - mae: 587.9161\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.1127 - mae: 588.1127\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.8228 - mae: 588.8228\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.3043 - mae: 587.3043\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.7715 - mae: 587.7715\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.4604 - mae: 588.4604\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.6821 - mae: 588.6821\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.6033 - mae: 588.6033\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3401 - mae: 589.3401\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.2428 - mae: 589.2428\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.6104 - mae: 589.6104\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.1153 - mae: 590.1153\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.3151 - mae: 590.3151\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.1270 - mae: 591.1270\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4148 - mae: 591.4148\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4802 - mae: 591.4802\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0092 - mae: 592.0092\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.5182 - mae: 590.5182\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.8817 - mae: 590.8817\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.3186 - mae: 591.3186\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9951 - mae: 591.9951\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.8550 - mae: 591.8550\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.5441 - mae: 590.5441\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.7087 - mae: 590.7087\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.4279 - mae: 591.4279\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.6808 - mae: 591.6808\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.3016 - mae: 592.3016\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.9266 - mae: 590.9266\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.7641 - mae: 589.7641\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.3864 - mae: 590.3864\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.2023 - mae: 589.2023\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3804 - mae: 589.3804\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.7336 - mae: 589.7336\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.8677 - mae: 589.8677\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.3649 - mae: 588.3649\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.9877 - mae: 586.9877\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.0283 - mae: 587.0283\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.9909 - mae: 586.9909\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.3352 - mae: 587.3352\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.9550 - mae: 587.9550\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4496 - mae: 586.4496\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4003 - mae: 586.4003\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.4794 - mae: 585.4794\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 585.9949 - mae: 585.9949\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.0495 - mae: 586.0495\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.3655 - mae: 586.3655\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.3515 - mae: 586.3515\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4989 - mae: 586.4989\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.8454 - mae: 586.8454\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.7955 - mae: 586.7955\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.5361 - mae: 585.5361\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.7674 - mae: 585.7674\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.0890 - mae: 586.0890\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.2244 - mae: 586.2244\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.2988 - mae: 586.2988\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.0687 - mae: 587.0687\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.7626 - mae: 587.7626\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.1389 - mae: 588.1389\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.7886 - mae: 588.7886\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.2233 - mae: 587.2233\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.9383 - mae: 585.9383\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.6765 - mae: 586.6765\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.3227 - mae: 587.3227\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.2280 - mae: 587.2280\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.6081 - mae: 587.6081\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.3876 - mae: 586.3876\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.3907 - mae: 585.3907\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.9464 - mae: 584.9464\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.4423 - mae: 584.4423\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.9842 - mae: 583.9842\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5390 - mae: 583.5390\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5752 - mae: 583.5752\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1242 - mae: 583.1242\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4301 - mae: 583.4301\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.6171 - mae: 583.6171\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.8696 - mae: 583.8696\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.0178 - mae: 584.0178\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.1710 - mae: 584.1710\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.3937 - mae: 584.3937\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.5561 - mae: 584.5561\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.5609 - mae: 584.5609\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.0867 - mae: 584.0867\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.3979 - mae: 584.3979\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.6523 - mae: 584.6523\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.8256 - mae: 584.8256\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.8395 - mae: 584.8395\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.3938 - mae: 584.3938\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.9346 - mae: 583.9346\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.1290 - mae: 584.1290\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.6597 - mae: 583.6597\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2039 - mae: 583.2039\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7008 - mae: 582.7008\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7557 - mae: 582.7557\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.0690 - mae: 583.0690\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2142 - mae: 583.2142\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4628 - mae: 583.4628\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.9454 - mae: 582.9454\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.1551 - mae: 583.1551\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4257 - mae: 583.4257\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5399 - mae: 583.5399\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.7999 - mae: 583.7999\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2510 - mae: 583.2510\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7483 - mae: 582.7483\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.2554 - mae: 582.2554\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.8232 - mae: 581.8232\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0750 - mae: 582.0750\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2162 - mae: 582.2162\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.4127 - mae: 582.4127\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.4841 - mae: 582.4841\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.9490 - mae: 581.9490\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2248 - mae: 582.2248\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.4114 - mae: 582.4114\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.4919 - mae: 582.4919\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.9847 - mae: 581.9847\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.1620 - mae: 582.1620\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2626 - mae: 582.2626\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.3130 - mae: 582.3130\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.5682 - mae: 582.5682\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.5511 - mae: 582.5511\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5898 - mae: 582.5898\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.6740 - mae: 582.6740\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.8244 - mae: 582.8244\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1351 - mae: 583.1351\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2140 - mae: 583.2140\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7871 - mae: 582.7871\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.0973 - mae: 583.0973\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5933 - mae: 582.5933\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.6193 - mae: 582.6193\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.8243 - mae: 582.8243\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.3929 - mae: 582.3929\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.6532 - mae: 582.6532\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7490 - mae: 582.7490\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.0261 - mae: 583.0261\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.0205 - mae: 583.0205\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1463 - mae: 583.1463\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2468 - mae: 583.2468\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7894 - mae: 582.7894\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.3339 - mae: 582.3339\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5852 - mae: 582.5852\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0219 - mae: 582.0219\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0164 - mae: 582.0164\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1373 - mae: 582.1373\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1292 - mae: 582.1292\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.6201 - mae: 581.6201\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.9284 - mae: 581.9284\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1237 - mae: 582.1237\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1399 - mae: 582.1399\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.1765 - mae: 582.1765\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.7180 - mae: 581.7180\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.7115 - mae: 581.7115\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.1503 - mae: 581.1503\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.6573 - mae: 580.6573\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.2112 - mae: 580.2112\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.2269 - mae: 580.2269\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 579.7603 - mae: 579.7603\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 579.2328 - mae: 579.2328\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.7835 - mae: 578.7835\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.9604 - mae: 578.9604\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.4328 - mae: 578.4328\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.4529 - mae: 578.4529\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.7214 - mae: 578.7214\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.7625 - mae: 578.7625\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1999 - mae: 578.1999\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7474 - mae: 577.7474\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.8856 - mae: 577.8856\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1741 - mae: 578.1741\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.3800 - mae: 578.3800\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.9214 - mae: 577.9214\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1312 - mae: 578.1312\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.5746 - mae: 577.5746\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7109 - mae: 577.7109\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.8140 - mae: 577.8140\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.8892 - mae: 577.8892\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.0350 - mae: 578.0350\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.1135 - mae: 578.1135\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1143 - mae: 578.1143\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.3344 - mae: 578.3344\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7866 - mae: 577.7866\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.0532 - mae: 578.0532\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.2394 - mae: 578.2394\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7468 - mae: 577.7468\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.9627 - mae: 577.9627\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.5062 - mae: 577.5062\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.0149 - mae: 577.0149\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.5225 - mae: 576.5225\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.5485 - mae: 576.5485\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.7583 - mae: 576.7583\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2043 - mae: 576.2043\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.3799 - mae: 576.3799\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.8873 - mae: 575.8873\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.4307 - mae: 575.4307\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.9482 - mae: 574.9482\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.1525 - mae: 575.1525\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.3397 - mae: 575.3397\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.4316 - mae: 575.4316\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7809 - mae: 575.7809\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.8145 - mae: 575.8145\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.1207 - mae: 576.1207\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.3036 - mae: 576.3036\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.6118 - mae: 576.6118\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.1654 - mae: 576.1654\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7224 - mae: 575.7224\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.9795 - mae: 575.9795\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.9841 - mae: 575.9841\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.0093 - mae: 576.0093\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2048 - mae: 576.2048\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7493 - mae: 575.7493\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0063 - mae: 576.0063\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.2017 - mae: 576.2017\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7471 - mae: 575.7471\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0159 - mae: 576.0159\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.2354 - mae: 576.2354\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.6900 - mae: 575.6900\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.8125 - mae: 575.8125\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.3401 - mae: 575.3401\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5196 - mae: 575.5196\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.6477 - mae: 575.6477\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7897 - mae: 575.7897\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7904 - mae: 575.7904\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0071 - mae: 576.0071\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5286 - mae: 575.5286\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5991 - mae: 575.5991\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.0967 - mae: 575.0967\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5966 - mae: 574.5966\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.7010 - mae: 574.7010\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2533 - mae: 574.2533\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.6765 - mae: 574.6765\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5615 - mae: 574.5615\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9966 - mae: 574.9966\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9592 - mae: 574.9592\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5099 - mae: 575.5099\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.0167 - mae: 576.0167\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7744 - mae: 575.7744\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2180 - mae: 576.2180\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.9397 - mae: 575.9397\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5928 - mae: 575.5928\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.5457 - mae: 575.5457\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.2789 - mae: 575.2789\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.0942 - mae: 575.0942\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7821 - mae: 574.7821\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.2740 - mae: 575.2740\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7286 - mae: 575.7286\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.3907 - mae: 575.3907\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.1941 - mae: 575.1941\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9971 - mae: 574.9971\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7311 - mae: 574.7311\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6040 - mae: 574.6040\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4524 - mae: 574.4524\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9716 - mae: 574.9716\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5383 - mae: 574.5383\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3650 - mae: 574.3650\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1693 - mae: 574.1693\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2520 - mae: 574.2520\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5074 - mae: 574.5074\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6917 - mae: 574.6917\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.8866 - mae: 574.8866\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4290 - mae: 574.4290\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4460 - mae: 574.4460\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2506 - mae: 574.2506\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1930 - mae: 574.1930\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3293 - mae: 574.3293\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3347 - mae: 574.3347\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3177 - mae: 574.3177\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2595 - mae: 574.2595\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2125 - mae: 574.2125\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4901 - mae: 574.4901\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6849 - mae: 574.6849\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.6893 - mae: 574.6893\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2422 - mae: 574.2422\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.4521 - mae: 574.4521\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2275 - mae: 574.2275\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2036 - mae: 574.2036\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2944 - mae: 574.2944\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.5218 - mae: 574.5218\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7402 - mae: 574.7402\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2195 - mae: 574.2195\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3665 - mae: 574.3665\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2777 - mae: 574.2777\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1354 - mae: 574.1354\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.3242 - mae: 574.3242\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4412 - mae: 574.4412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd706c70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "# Make model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model_3.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model_3.fit(xtr, ytr, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Mse: 306998.09375 | Mae: 406.56842041015625\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_3 = model_3.predict(xte)\n",
    "\n",
    "see(y_preds_3, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=306998.1>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_preds_3, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model1</td>\n",
       "      <td>402.489502</td>\n",
       "      <td>626321.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model2</td>\n",
       "      <td>336.789917</td>\n",
       "      <td>292507.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model3</td>\n",
       "      <td>406.568420</td>\n",
       "      <td>306998.09375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model         mae           mse\n",
       "0  Model1  402.489502  626321.68750\n",
       "1  Model2  336.789917  292507.37500\n",
       "2  Model3  406.568420  306998.09375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = [\n",
    "    [\"Model1\", mae(y_preds_1, yte).numpy(), mse(y_preds_1, yte).numpy()],\n",
    "    [\"Model2\", mae(y_preds_2, yte).numpy(), mse(y_preds_2, yte).numpy()],\n",
    "    [\"Model3\", mae(y_preds_3, yte).numpy(), mse(y_preds_3, yte).numpy()]\n",
    "]\n",
    "\n",
    "model_results = pd.DataFrame(models_results, columns=[\"model\", \"mae\", \"mse\"])\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer (Dense)         (1, 10)                   20        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 1)                    11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 2 was the better\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your main goal is to minimize the time between training sessions, because the more ou try different things and works in cicle, the more you discover the things that dont work, and the more you aproximate the better possible model, remember the machine learning people motto: experiment, experiment, experiment!\n",
    "\n",
    "This is the reason why you compare models! You try simple models first, see the best, try variatons of the best, take the best, and move on!\n",
    "\n",
    "Now we are gonna stop testing because this is a course, but in real life, you wold take model 2 and move on with the exprimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking your experiments (This is a very, very, good practice)\n",
    "\n",
    "We have tools for this:\n",
    "\n",
    "* TensorBoard\n",
    "* Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving your models\n",
    "\n",
    "2 Ways:\n",
    "\n",
    "* SavedModel format\n",
    "* HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) InputLayer with unsupported characters which will be renamed to inputlayer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model with SavedModel\n",
    "model_2.save(\"model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with hdf5\n",
    "model_2.save(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer (Dense)         (1, 10)                   20        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 1)                    11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load from savedModel\n",
    "l_model = tf.keras.models.load_model(\"model2\")\n",
    "l_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer (Dense)         (1, 10)                   20        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 1)                    11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load from h5 five format\n",
    "h_model = tf.keras.models.load_model(\"model2.h5\")\n",
    "h_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of all topics at this module\n",
    "\n",
    "## Lets do all the steps learned at this notebook again, with a more \"real\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 12973.1172 - mae: 12973.1172\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 12966.0010 - mae: 12966.0010\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 12950.5918 - mae: 12950.5918\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 12921.6396 - mae: 12921.6396\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 12873.3184 - mae: 12873.3184\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 12799.6582 - mae: 12799.6582\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 12694.7188 - mae: 12694.7188\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 12552.8291 - mae: 12552.8291\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 12368.2949 - mae: 12368.2949\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 12135.7754 - mae: 12135.7754\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 11850.1465 - mae: 11850.1465\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 11508.8623 - mae: 11508.8623\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 11120.1279 - mae: 11120.1279\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 10711.8760 - mae: 10711.8760\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 10312.6064 - mae: 10312.6064\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 9926.1475 - mae: 9926.1475\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 9537.8701 - mae: 9537.8701\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 9183.7012 - mae: 9183.7012\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 8870.0098 - mae: 8870.0098\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8595.7471 - mae: 8595.7471\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 893us/step - loss: 8377.0459 - mae: 8377.0459\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8184.6011 - mae: 8184.6011\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 8034.2378 - mae: 8034.2378\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7912.5386 - mae: 7912.5386\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7822.7266 - mae: 7822.7266\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7750.8115 - mae: 7750.8115\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7691.6533 - mae: 7691.6533\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7643.6406 - mae: 7643.6406\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 7601.1680 - mae: 7601.1680\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7562.3101 - mae: 7562.3101\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 7525.8276 - mae: 7525.8276\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7491.0303 - mae: 7491.0303\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7454.3506 - mae: 7454.3506\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7418.8057 - mae: 7418.8057\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 7382.7686 - mae: 7382.7686\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7347.1509 - mae: 7347.1509\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 7309.2144 - mae: 7309.2144\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7270.6255 - mae: 7270.6255\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 7232.2993 - mae: 7232.2993\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7194.5298 - mae: 7194.5298\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7154.3545 - mae: 7154.3545\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7113.1606 - mae: 7113.1606\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 7074.0581 - mae: 7074.0581\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7029.9951 - mae: 7029.9951\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6987.5728 - mae: 6987.5728\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6942.2021 - mae: 6942.2021\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6896.9932 - mae: 6896.9932\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6852.1138 - mae: 6852.1138\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 6802.2695 - mae: 6802.2695\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 6751.5576 - mae: 6751.5576\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6701.2891 - mae: 6701.2891\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 6647.7612 - mae: 6647.7612\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6593.0259 - mae: 6593.0259\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6536.5747 - mae: 6536.5747\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6479.0811 - mae: 6479.0811\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 946us/step - loss: 6417.3374 - mae: 6417.3374\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6352.9702 - mae: 6352.9702\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6286.5400 - mae: 6286.5400\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6218.1338 - mae: 6218.1338\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6146.9604 - mae: 6146.9604\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6071.9321 - mae: 6071.9321\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 5996.7339 - mae: 5996.7339\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5915.7573 - mae: 5915.7573\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 5828.6997 - mae: 5828.6997\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 5740.5981 - mae: 5740.5981\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5649.9033 - mae: 5649.9033\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 5551.0181 - mae: 5551.0181\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5452.5889 - mae: 5452.5889\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 5349.0811 - mae: 5349.0811\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 5244.0864 - mae: 5244.0864\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 5133.7197 - mae: 5133.7197\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5021.8193 - mae: 5021.8193\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 4912.8237 - mae: 4912.8237\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 961us/step - loss: 4795.0874 - mae: 4795.0874\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 4677.1270 - mae: 4677.1270\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 4563.5972 - mae: 4563.5972\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 4450.4727 - mae: 4450.4727\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 877us/step - loss: 4342.2090 - mae: 4342.2090\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 4232.4834 - mae: 4232.4834\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 942us/step - loss: 4131.8818 - mae: 4131.8818\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 4038.1602 - mae: 4038.1602\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3948.8494 - mae: 3948.8494\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3864.9021 - mae: 3864.9021\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 994us/step - loss: 3788.8923 - mae: 3788.8923\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 924us/step - loss: 3724.9851 - mae: 3724.9851\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3672.2869 - mae: 3672.2869\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 913us/step - loss: 3622.3147 - mae: 3622.3147\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3587.1721 - mae: 3587.1721\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3562.5698 - mae: 3562.5698\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3544.1372 - mae: 3544.1372\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3533.2324 - mae: 3533.2324\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 908us/step - loss: 3525.4082 - mae: 3525.4082\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3520.6382 - mae: 3520.6382\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 963us/step - loss: 3512.9644 - mae: 3512.9644\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3509.9160 - mae: 3509.9160\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 851us/step - loss: 3506.4758 - mae: 3506.4758\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3505.6804 - mae: 3505.6804\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3505.0686 - mae: 3505.0686\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3502.8904 - mae: 3502.8904\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 905us/step - loss: 3500.0864 - mae: 3500.0864\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3501.5042 - mae: 3501.5042\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3499.3274 - mae: 3499.3274\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3498.3542 - mae: 3498.3542\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3496.9551 - mae: 3496.9551\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3497.1643 - mae: 3497.1643\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3496.5898 - mae: 3496.5898\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 950us/step - loss: 3495.2078 - mae: 3495.2078\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3494.6423 - mae: 3494.6423\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 974us/step - loss: 3495.0505 - mae: 3495.0505\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 3494.1733 - mae: 3494.1733\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3493.3013 - mae: 3493.3013\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3494.6013 - mae: 3494.6013\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3491.8826 - mae: 3491.8826\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3491.5195 - mae: 3491.5195\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3490.6555 - mae: 3490.6555\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3490.2476 - mae: 3490.2476\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 919us/step - loss: 3489.7688 - mae: 3489.7688\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3488.4727 - mae: 3488.4727\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3489.5520 - mae: 3489.5520\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 921us/step - loss: 3489.2007 - mae: 3489.2007\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3488.3918 - mae: 3488.3918\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3487.2417 - mae: 3487.2417\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3488.5256 - mae: 3488.5256\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3486.5938 - mae: 3486.5938\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3487.2712 - mae: 3487.2712\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3487.3425 - mae: 3487.3425\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3486.0564 - mae: 3486.0564\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 924us/step - loss: 3486.1948 - mae: 3486.1948\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3484.8940 - mae: 3484.8940\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3485.6013 - mae: 3485.6013\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3485.2083 - mae: 3485.2083\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3483.7161 - mae: 3483.7161\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3484.0063 - mae: 3484.0063\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3483.7793 - mae: 3483.7793\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3481.8489 - mae: 3481.8489\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3481.4651 - mae: 3481.4651\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3482.2830 - mae: 3482.2830\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3481.4587 - mae: 3481.4587\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3481.8140 - mae: 3481.8140\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3480.6606 - mae: 3480.6606\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3480.8450 - mae: 3480.8450\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3480.5698 - mae: 3480.5698\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3479.2026 - mae: 3479.2026\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3478.1841 - mae: 3478.1841\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3478.3738 - mae: 3478.3738\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3484.0403 - mae: 3484.0403\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3477.9036 - mae: 3477.9036\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3477.1226 - mae: 3477.1226\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3477.0042 - mae: 3477.0042\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3476.1411 - mae: 3476.1411\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3477.7883 - mae: 3477.7883\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3475.4316 - mae: 3475.4316\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3476.1033 - mae: 3476.1033\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3475.6052 - mae: 3475.6052\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3474.5854 - mae: 3474.5854\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3473.8611 - mae: 3473.8611\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3474.9062 - mae: 3474.9062\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3476.6743 - mae: 3476.6743\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3471.7317 - mae: 3471.7317\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3472.6536 - mae: 3472.6536\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3473.1992 - mae: 3473.1992\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3471.4297 - mae: 3471.4297\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3471.5181 - mae: 3471.5181\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3471.4924 - mae: 3471.4924\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 974us/step - loss: 3470.0544 - mae: 3470.0544\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3470.9941 - mae: 3470.9941\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3468.2888 - mae: 3468.2888\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3468.9648 - mae: 3468.9648\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3468.3254 - mae: 3468.3254\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3468.4204 - mae: 3468.4204\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3468.4153 - mae: 3468.4153\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3468.2297 - mae: 3468.2297\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3466.8613 - mae: 3466.8613\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3466.2837 - mae: 3466.2837\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3465.9421 - mae: 3465.9421\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3467.0496 - mae: 3467.0496\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3465.8423 - mae: 3465.8423\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3463.9568 - mae: 3463.9568\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3462.9741 - mae: 3462.9741\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3462.7559 - mae: 3462.7559\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3462.8696 - mae: 3462.8696\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3463.6250 - mae: 3463.6250\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3462.3145 - mae: 3462.3145\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3462.3533 - mae: 3462.3533\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3460.9675 - mae: 3460.9675\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 3464.2356 - mae: 3464.2356\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3459.0261 - mae: 3459.0261\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3459.1108 - mae: 3459.1108\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3458.8411 - mae: 3458.8411\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3460.2180 - mae: 3460.2180\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 980us/step - loss: 3460.4177 - mae: 3460.4177\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3457.8669 - mae: 3457.8669\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3458.3826 - mae: 3458.3826\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3456.0723 - mae: 3456.0723\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3456.8884 - mae: 3456.8884\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3457.5391 - mae: 3457.5391\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3456.3911 - mae: 3456.3911\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3456.7429 - mae: 3456.7429\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3453.9158 - mae: 3453.9158\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3456.2417 - mae: 3456.2417\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3454.0825 - mae: 3454.0825\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3452.2300 - mae: 3452.2300\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3453.5251 - mae: 3453.5251\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3453.7593 - mae: 3453.7593\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3450.9263 - mae: 3450.9263\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3451.7585 - mae: 3451.7585\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3450.8687 - mae: 3450.8687\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3450.4680 - mae: 3450.4680\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3451.6011 - mae: 3451.6011\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3449.1062 - mae: 3449.1062\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3449.1055 - mae: 3449.1055\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 3449.5386 - mae: 3449.5386\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3448.4827 - mae: 3448.4827\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3446.8772 - mae: 3446.8772\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3448.0383 - mae: 3448.0383\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3446.0308 - mae: 3446.0308\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3446.3367 - mae: 3446.3367\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3445.8723 - mae: 3445.8723\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3444.5444 - mae: 3444.5444\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3443.4160 - mae: 3443.4160\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3443.3103 - mae: 3443.3103\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3443.1582 - mae: 3443.1582\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3442.4827 - mae: 3442.4827\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 3443.2678 - mae: 3443.2678\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3440.9863 - mae: 3440.9863\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3442.1089 - mae: 3442.1089\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3440.5046 - mae: 3440.5046\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3440.3672 - mae: 3440.3672\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3442.0740 - mae: 3442.0740\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3440.6975 - mae: 3440.6975\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3438.3608 - mae: 3438.3608\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3437.7517 - mae: 3437.7517\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3436.8789 - mae: 3436.8789\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3436.8628 - mae: 3436.8628\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3437.3262 - mae: 3437.3262\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3437.5249 - mae: 3437.5249\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3436.5486 - mae: 3436.5486\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3436.0681 - mae: 3436.0681\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3434.9800 - mae: 3434.9800\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3434.9709 - mae: 3434.9709\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 973us/step - loss: 3434.2524 - mae: 3434.2524\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3434.2131 - mae: 3434.2131\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3433.7656 - mae: 3433.7656\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 905us/step - loss: 3432.7544 - mae: 3432.7544\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3434.3286 - mae: 3434.3286\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3435.8203 - mae: 3435.8203\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3434.3557 - mae: 3434.3557\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3433.5505 - mae: 3433.5505\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 3432.0481 - mae: 3432.0481\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3433.4626 - mae: 3433.4626\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3432.8042 - mae: 3432.8042\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3431.3064 - mae: 3431.3064\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 920us/step - loss: 3431.4163 - mae: 3431.4163\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3432.7012 - mae: 3432.7012\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 3435.4924 - mae: 3435.4924\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3432.9885 - mae: 3432.9885\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3430.9800 - mae: 3430.9800\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3430.9695 - mae: 3430.9695\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3431.2305 - mae: 3431.2305\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 961us/step - loss: 3430.8572 - mae: 3430.8572\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3429.3618 - mae: 3429.3618\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3429.4846 - mae: 3429.4846\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3430.1785 - mae: 3430.1785\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3428.7844 - mae: 3428.7844\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3429.7795 - mae: 3429.7795\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3430.0571 - mae: 3430.0571\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3430.2761 - mae: 3430.2761\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3429.3909 - mae: 3429.3909\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3427.5054 - mae: 3427.5054\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3427.9060 - mae: 3427.9060\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 924us/step - loss: 3428.8086 - mae: 3428.8086\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3428.3882 - mae: 3428.3882\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3429.6077 - mae: 3429.6077\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3427.4375 - mae: 3427.4375\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 983us/step - loss: 3427.8198 - mae: 3427.8198\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 979us/step - loss: 3429.5347 - mae: 3429.5347\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3428.0969 - mae: 3428.0969\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3428.5002 - mae: 3428.5002\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3429.0786 - mae: 3429.0786\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3427.7566 - mae: 3427.7566\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 987us/step - loss: 3426.5261 - mae: 3426.5261\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 937us/step - loss: 3426.3938 - mae: 3426.3938\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3425.6919 - mae: 3425.6919\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 908us/step - loss: 3426.3105 - mae: 3426.3105\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3425.4102 - mae: 3425.4102\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3427.8784 - mae: 3427.8784\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3425.6355 - mae: 3425.6355\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3424.5649 - mae: 3424.5649\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3424.5664 - mae: 3424.5664\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3425.7156 - mae: 3425.7156\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3424.0239 - mae: 3424.0239\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3425.6411 - mae: 3425.6411\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3425.4448 - mae: 3425.4448\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3424.1414 - mae: 3424.1414\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3426.1570 - mae: 3426.1570\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3425.6582 - mae: 3425.6582\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 945us/step - loss: 3424.7795 - mae: 3424.7795\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3423.3843 - mae: 3423.3843\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3424.7329 - mae: 3424.7329\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3423.5933 - mae: 3423.5933\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3422.7180 - mae: 3422.7180\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3423.5090 - mae: 3423.5090\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3422.7185 - mae: 3422.7185\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 993us/step - loss: 3424.7971 - mae: 3424.7971\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3422.6526 - mae: 3422.6526\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 858us/step - loss: 3422.6262 - mae: 3422.6262\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3422.5989 - mae: 3422.5989\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 937us/step - loss: 3421.6226 - mae: 3421.6226\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3421.2266 - mae: 3421.2266\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3421.6555 - mae: 3421.6555\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3421.0649 - mae: 3421.0649\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.7788 - mae: 3420.7788\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 3420.5896 - mae: 3420.5896\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.7778 - mae: 3420.7778\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 924us/step - loss: 3420.1431 - mae: 3420.1431\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3419.9373 - mae: 3419.9373\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.2273 - mae: 3420.2273\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3420.8279 - mae: 3420.8279\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.7114 - mae: 3420.7114\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3419.8220 - mae: 3419.8220\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3421.6858 - mae: 3421.6858\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3422.2346 - mae: 3422.2346\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3422.2634 - mae: 3422.2634\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.6418 - mae: 3419.6418\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3419.7637 - mae: 3419.7637\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.2522 - mae: 3420.2522\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3419.7898 - mae: 3419.7898\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.3289 - mae: 3420.3289\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 954us/step - loss: 3418.4709 - mae: 3418.4709\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.6516 - mae: 3419.6516\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.2288 - mae: 3419.2288\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.1216 - mae: 3418.1216\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.9194 - mae: 3419.9194\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3420.2180 - mae: 3420.2180\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.2463 - mae: 3420.2463\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3419.4934 - mae: 3419.4934\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.1929 - mae: 3419.1929\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.8103 - mae: 3419.8103\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.6404 - mae: 3418.6404\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.2026 - mae: 3419.2026\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.9761 - mae: 3418.9761\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.7292 - mae: 3420.7292\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.3940 - mae: 3419.3940\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.4905 - mae: 3419.4905\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.3860 - mae: 3418.3860\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.5171 - mae: 3420.5171\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.8708 - mae: 3418.8708\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.4995 - mae: 3417.4995\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.0740 - mae: 3418.0740\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.2498 - mae: 3418.2498\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3420.3716 - mae: 3420.3716\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3418.1965 - mae: 3418.1965\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.1353 - mae: 3417.1353\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.3237 - mae: 3417.3237\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.2346 - mae: 3418.2346\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3417.9141 - mae: 3417.9141\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3418.7507 - mae: 3418.7507\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.4944 - mae: 3417.4944\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3416.7983 - mae: 3416.7983\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3417.0503 - mae: 3417.0503\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3417.7825 - mae: 3417.7825\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 916us/step - loss: 3416.4888 - mae: 3416.4888\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.2854 - mae: 3417.2854\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3418.4941 - mae: 3418.4941\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3416.0452 - mae: 3416.0452\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.7532 - mae: 3417.7532\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3416.2483 - mae: 3416.2483\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3416.7839 - mae: 3416.7839\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 872us/step - loss: 3416.1282 - mae: 3416.1282\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 998us/step - loss: 3420.4788 - mae: 3420.4788\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 905us/step - loss: 3416.4160 - mae: 3416.4160\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3416.9807 - mae: 3416.9807\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 850us/step - loss: 3417.6082 - mae: 3417.6082\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3415.7280 - mae: 3415.7280\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3416.7266 - mae: 3416.7266\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3416.4924 - mae: 3416.4924\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3416.2773 - mae: 3416.2773\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3419.8005 - mae: 3419.8005\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3415.4670 - mae: 3415.4670\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3415.7639 - mae: 3415.7639\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3416.2258 - mae: 3416.2258\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3415.8025 - mae: 3415.8025\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3415.8601 - mae: 3415.8601\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.8237 - mae: 3417.8237\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 924us/step - loss: 3417.3601 - mae: 3417.3601\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3418.2551 - mae: 3418.2551\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3416.1047 - mae: 3416.1047\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3415.1736 - mae: 3415.1736\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3415.4934 - mae: 3415.4934\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3415.5220 - mae: 3415.5220\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3418.5698 - mae: 3418.5698\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3414.3047 - mae: 3414.3047\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3419.7930 - mae: 3419.7930\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3414.2107 - mae: 3414.2107\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.1096 - mae: 3417.1096\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3414.4475 - mae: 3414.4475\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3415.1814 - mae: 3415.1814\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3414.5391 - mae: 3414.5391\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3416.9417 - mae: 3416.9417\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3415.3411 - mae: 3415.3411\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3414.3589 - mae: 3414.3589\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3415.6792 - mae: 3415.6792\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 967us/step - loss: 3414.5078 - mae: 3414.5078\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3414.0193 - mae: 3414.0193\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3413.8477 - mae: 3413.8477\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3414.0278 - mae: 3414.0278\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3414.2302 - mae: 3414.2302\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3415.1460 - mae: 3415.1460\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.0852 - mae: 3417.0852\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3414.9141 - mae: 3414.9141\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3414.0134 - mae: 3414.0134\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.0837 - mae: 3413.0837\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3413.5735 - mae: 3413.5735\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.9460 - mae: 3413.9460\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.9390 - mae: 3413.9390\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.2207 - mae: 3413.2207\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3417.2917 - mae: 3417.2917\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.8367 - mae: 3413.8367\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3416.3906 - mae: 3416.3906\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.3738 - mae: 3413.3738\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3413.2571 - mae: 3413.2571\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3412.9351 - mae: 3412.9351\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.8689 - mae: 3412.8689\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.4163 - mae: 3413.4163\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.8904 - mae: 3412.8904\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3414.3145 - mae: 3414.3145\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 998us/step - loss: 3413.4871 - mae: 3413.4871\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.4595 - mae: 3413.4595\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3417.5854 - mae: 3417.5854\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.9575 - mae: 3413.9575\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 941us/step - loss: 3413.2668 - mae: 3413.2668\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.6763 - mae: 3412.6763\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.4917 - mae: 3412.4917\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3412.8091 - mae: 3412.8091\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3411.7134 - mae: 3411.7134\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3411.5796 - mae: 3411.5796\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3412.4265 - mae: 3412.4265\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.4883 - mae: 3413.4883\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 908us/step - loss: 3411.4985 - mae: 3411.4985\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3415.4141 - mae: 3415.4141\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3411.9866 - mae: 3411.9866\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 899us/step - loss: 3414.2168 - mae: 3414.2168\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3413.0098 - mae: 3413.0098\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3410.7947 - mae: 3410.7947\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3410.7329 - mae: 3410.7329\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.9739 - mae: 3412.9739\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.1887 - mae: 3412.1887\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.6426 - mae: 3412.6426\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3410.9136 - mae: 3410.9136\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 974us/step - loss: 3409.8711 - mae: 3409.8711\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3412.1628 - mae: 3412.1628\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 945us/step - loss: 3411.8606 - mae: 3411.8606\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3411.4431 - mae: 3411.4431\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3410.9246 - mae: 3410.9246\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3410.7942 - mae: 3410.7942\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3411.5676 - mae: 3411.5676\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3410.7166 - mae: 3410.7166\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3410.7839 - mae: 3410.7839\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3414.8655 - mae: 3414.8655\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 996us/step - loss: 3409.9739 - mae: 3409.9739\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3410.2710 - mae: 3410.2710\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 877us/step - loss: 3412.3979 - mae: 3412.3979\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3413.1660 - mae: 3413.1660\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 887us/step - loss: 3408.8945 - mae: 3408.8945\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3409.3550 - mae: 3409.3550\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3409.4924 - mae: 3409.4924\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.5090 - mae: 3412.5090\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 989us/step - loss: 3409.5989 - mae: 3409.5989\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3410.0686 - mae: 3410.0686\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3409.9626 - mae: 3409.9626\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3408.7734 - mae: 3408.7734\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3409.3882 - mae: 3409.3882\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 924us/step - loss: 3410.8418 - mae: 3410.8418\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3409.5957 - mae: 3409.5957\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3410.4692 - mae: 3410.4692\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 989us/step - loss: 3409.1228 - mae: 3409.1228\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3408.7732 - mae: 3408.7732\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3410.0591 - mae: 3410.0591\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3409.3345 - mae: 3409.3345\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 901us/step - loss: 3408.5579 - mae: 3408.5579\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3407.9800 - mae: 3407.9800\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 923us/step - loss: 3408.9839 - mae: 3408.9839\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3407.9016 - mae: 3407.9016\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3412.4260 - mae: 3412.4260\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 929us/step - loss: 3409.4836 - mae: 3409.4836\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3407.8474 - mae: 3407.8474\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3408.7600 - mae: 3408.7600\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 960us/step - loss: 3410.8469 - mae: 3410.8469\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3408.9360 - mae: 3408.9360\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3408.6243 - mae: 3408.6243\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3410.7263 - mae: 3410.7263\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3412.2410 - mae: 3412.2410\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 886us/step - loss: 3410.1433 - mae: 3410.1433\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3408.3286 - mae: 3408.3286\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3407.5288 - mae: 3407.5288\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3409.1753 - mae: 3409.1753\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3411.6638 - mae: 3411.6638\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3408.8933 - mae: 3408.8933\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3411.7285 - mae: 3411.7285\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3408.7109 - mae: 3408.7109\n"
     ]
    }
   ],
   "source": [
    "# Lets import the necessary modules\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "\n",
    "# Aplly log transofrm at y\n",
    "# df[\"charges\"] = df[\"charges\"].apply(lambda x: np.log(x))\n",
    "\n",
    "# X and Y\n",
    "X = df[[col for col in df.columns if col != \"charges\"]]\n",
    "Y = df[\"charges\"]\n",
    "\n",
    "# Make column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Separate train ans test data\n",
    "xtr, xte, ytr, yte = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "# Apply scaler and encoding with column transformer\n",
    "xtr = ct.fit_transform(xtr)\n",
    "xte = ct.transform(xte)\n",
    "\n",
    "# Make model\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "NN = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(11)),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile\n",
    "NN.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Adam(), metrics=[\"mae\"])\n",
    "\n",
    "# Fit\n",
    "history = NN.fit(xtr, ytr, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 748us/step - loss: 3424.3584 - mae: 3424.3584\n",
      "Model performance:\n",
      " MAE: 3424.3583984375\n"
     ]
    }
   ],
   "source": [
    "# Plot predictions against real value\n",
    "print(f\"Model performance:\\n MAE: {NN.evaluate(xte, yte)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model predictions\n",
    "yhat = pd.Series(NN.predict(xte).ravel())\n",
    "\n",
    "sns.scatterplot(x=yte, y=yhat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning history\n",
    "pd.DataFrame(history.history).plot();\n",
    "\n",
    "# --> The loss (y axis) decreases with more epochs, but it gets kinda stuck around epoch 300, consider early stopping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baf1db779f0cdc1ce48b1fe9bcd8ead02e6c1caf4dfdb394510f91c1920b3eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
