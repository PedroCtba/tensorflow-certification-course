{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor flow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Tensor flow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic architecture of a NN\n",
    "\n",
    "* Input layer: same as the number of samples\n",
    "* Hidden layer: Unlimited, minumum 1\n",
    "* Output layer: same as the number of desired outputs (number of classes, if regression, 1)\n",
    "\n",
    "***there are more parameters, they will be covered in more detail latter***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression problem, is simple words, is predicting a number, so lets get going! :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets create some data to fit\n",
    "X = np.array([number for number in range(0, 50)])\n",
    "\n",
    "rand = randint(0, 50) # -> Define a fixed random number that will multiply x\n",
    "Y = np.array([(number * rand) / np.cos(number/rand) for number in X])\n",
    "\n",
    "# Scater\n",
    "plt.scatter(X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But hold ON! If you try to train the model with this, you will encounter problems, bexause tensorflow 2.7+ requires the data to have at least 2 dimensions, in your case the data has 1 dimension mathematicaly speaking, and 0 (\"tensorflowing\" speaking)**\n",
    "\n",
    "***lets fix the data dimensions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "xtr = tf.expand_dims(xtr, axis=-1)\n",
    "xte = tf.expand_dims(xte, axis=-1)\n",
    "\n",
    "ytr = tf.expand_dims(ytr, axis=-1)\n",
    "yte = tf.expand_dims(yte, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is odd, but correct, because the input is a scalar, with has 0 dimensions in tensor flow, and the output as 0 dimensions too**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to build a regression neural network?\n",
    "\n",
    "#### Check bellow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1195.7161 - mae: 1195.7161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fc0a61f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let\"s build a model to fit this problem\n",
    "\n",
    "# Step 1: Create a model: Define the layers (input, hidden, output, and maybe others)\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Sequential([ # -> Sequential API make the layers in the coded order\n",
    "    tf.keras.layers.Dense(1) # -> Just one layer (with 1 neuron)\n",
    "])\n",
    "\n",
    "# Step 2: Compile the model \n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae, # Mean Absolute Error\n",
    "    optimizer=tf.keras.optimizers.SGD(), # Stochastic Gradient Descent\n",
    "    metrics=[\"mae\"] # See how the model is going with this metric\n",
    ")\n",
    "\n",
    "## Define the loss function: The funciton that says how much the model is wrong;\n",
    "## Define the optimizer: The funcitons that says how your model can improve;\n",
    "## Dine eval metrics: The functions that can interpret the performance of your model;\n",
    "\n",
    "# Step 3: Fitting the model: Letting the model find the relations\n",
    "model.fit(xtr, ytr, epochs=50) # -> How have 50 epochs to learn the patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to check model summary?\n",
    "\n",
    "- after fiting, just call model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# Model has 1 layer, which is the dense layer (Its building the input layer behind the scene, summary() doent show it)\n",
    "\n",
    "# it has 2 parameters, wich are the weights and biases, both are trainable for now, because i did not fixed them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary returns:\n",
    "- The output shape\n",
    "- The layers and its types\n",
    "- Trainable parameters: Number of parameters that the model can change while training\n",
    "- Total parameters: Total number of parameters\n",
    "- Non-trainable parameters: Freezed parameters, the model will not change these (normal when ussing pre saved models)\n",
    "\n",
    "What are this parameters?\n",
    "- Bias\n",
    "- Weights\n",
    "\n",
    "Learn more her: https://www.youtube.com/watch?v=7sB052Pz0sQ&ab_channel=AlexanderAmini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making more regression models\n",
    "\n",
    "## Metrics to validate predictions:\n",
    "\n",
    "* MAE\n",
    "* MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make evaluaction functions\n",
    "def mse(yhat, ytrue):\n",
    "    mse_e = tf.keras.losses.MeanSquaredError()\n",
    "    return mse_e(ytrue, yhat)\n",
    "\n",
    "def mae(yhat, ytrue):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()\n",
    "    return mae(ytrue, yhat)\n",
    "\n",
    "def see(yhat, ytrue):\n",
    "    print(f\"Mse: {mse(yhat, ytrue)} | Mae: {mae(yhat, ytrue)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to imporve the firt test model\n",
    "###### Data Scientists rule of thumb: experiment, experiment, experiment\n",
    "\n",
    "* Get more data\n",
    "* Make model larger\n",
    "* Train for longer periods\n",
    "\n",
    "**Lets try some things:**\n",
    "- Model 1: train for longer\n",
    "- Model 2: more epochs at train, and more layer\n",
    "- Model 3: train for 500 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "Training for longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1195.7161 - mae: 1195.7161\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1177.2498 - mae: 1177.2498\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.3679 - mae: 1165.3679\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1157.9121 - mae: 1157.9121\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1140.0149 - mae: 1140.0149\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1123.0496 - mae: 1123.0496\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1105.4407 - mae: 1105.4407\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1090.3107 - mae: 1090.3107\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1078.0863 - mae: 1078.0863\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1059.9420 - mae: 1059.9420\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1050.5829 - mae: 1050.5829\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1040.2543 - mae: 1040.2543\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1021.6632 - mae: 1021.6632\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1005.6870 - mae: 1005.6870\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 997.0180 - mae: 997.0180\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 986.2400 - mae: 986.2400\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 976.2129 - mae: 976.2129\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 959.7241 - mae: 959.7241\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 942.3572 - mae: 942.3572\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 934.7939 - mae: 934.7939\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 921.2932 - mae: 921.2932\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 908.2378 - mae: 908.2378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 901.5795 - mae: 901.5795\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 893.4252 - mae: 893.4252\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 876.0840 - mae: 876.0840\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 861.7178 - mae: 861.7178\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 843.6089 - mae: 843.6089\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 831.7204 - mae: 831.7204\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 814.4788 - mae: 814.4788\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 805.6436 - mae: 805.6436\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 795.7215 - mae: 795.7215\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 791.0927 - mae: 791.0927\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 778.2471 - mae: 778.2471\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 763.7402 - mae: 763.7402\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 750.1713 - mae: 750.1713\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 743.0460 - mae: 743.0460\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 741.2668 - mae: 741.2668\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 740.0448 - mae: 740.0448\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 736.8660 - mae: 736.8660\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 726.4778 - mae: 726.4778\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 719.2236 - mae: 719.2236\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 718.5413 - mae: 718.5413\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 711.2629 - mae: 711.2629\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 705.0186 - mae: 705.0186\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 704.3236 - mae: 704.3236\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 702.7917 - mae: 702.7917\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 701.0508 - mae: 701.0508\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.2601 - mae: 701.2601\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.7204 - mae: 701.7204\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 693.2158 - mae: 693.2158\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.7516 - mae: 685.7516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd5c7670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "model_1.fit(xtr, ytr, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Mse: 626321.6875 | Mae: 402.489501953125\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_1 = model_1.predict(xte)\n",
    "\n",
    "see(y_preds_1, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Training for longer, and incrasing number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1816.0175 - mae: 1816.0175\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1774.4366 - mae: 1774.4366\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1699.6813 - mae: 1699.6813\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1602.2974 - mae: 1602.2974\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1137.5853 - mae: 1137.5853\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 632.1163 - mae: 632.1163\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 952.4985 - mae: 952.4985\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 993.0396 - mae: 993.0396\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 660.8275 - mae: 660.8275\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 688.1006 - mae: 688.1006\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 765.9018 - mae: 765.9018\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 821.7432 - mae: 821.7432\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1297.3496 - mae: 1297.3496\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 819.4653 - mae: 819.4653\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 807.3270 - mae: 807.3270\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1048.9618 - mae: 1048.9618\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1977.7429 - mae: 1977.7429\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.9372 - mae: 595.9372\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 943.3069 - mae: 943.3069\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 988.6705 - mae: 988.6705\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 585.9211 - mae: 585.9211\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 878.8668 - mae: 878.8668\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 886.7725 - mae: 886.7725\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 969.3975 - mae: 969.3975\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1108.2845 - mae: 1108.2845\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.0402 - mae: 578.0402\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 847.5024 - mae: 847.5024\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1010.5807 - mae: 1010.5807\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 737.3079 - mae: 737.3079\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1210.5717 - mae: 1210.5717\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1039.8683 - mae: 1039.8683\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 795.6148 - mae: 795.6148\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.1860 - mae: 587.1860\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1617.1428 - mae: 1617.1428\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2308.2720 - mae: 2308.2720\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3373.3203 - mae: 3373.3203\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 690.9224 - mae: 690.9224\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1833.9457 - mae: 1833.9457\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 645.0174 - mae: 645.0174\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 851.1540 - mae: 851.1540\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 785.9974 - mae: 785.9974\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 981.6179 - mae: 981.6179\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1026.8684 - mae: 1026.8684\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3821 - mae: 589.3821\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.9394 - mae: 589.9394\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 775.0917 - mae: 775.0917\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 869.0668 - mae: 869.0668\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1029.5314 - mae: 1029.5314\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 752.2701 - mae: 752.2701\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1491.5623 - mae: 1491.5623\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2223.4536 - mae: 2223.4536\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 608.1695 - mae: 608.1695\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.0791 - mae: 590.0791\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1409.7762 - mae: 1409.7762\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1867.8629 - mae: 1867.8629\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2562.5256 - mae: 2562.5256\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 780.3823 - mae: 780.3823\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 830.4994 - mae: 830.4994\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1455.4287 - mae: 1455.4287\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.4639 - mae: 599.4639\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 680.0636 - mae: 680.0636\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1498.7717 - mae: 1498.7717\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1118.0316 - mae: 1118.0316\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 881.1511 - mae: 881.1511\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 800.6207 - mae: 800.6207\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 637.9025 - mae: 637.9025\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1204.2213 - mae: 1204.2213\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2059.0020 - mae: 2059.0020\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.2132 - mae: 581.2132\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 895.0942 - mae: 895.0942\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1053.3883 - mae: 1053.3883\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 658.4936 - mae: 658.4936\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.0495 - mae: 597.0495\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1196.0315 - mae: 1196.0315\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 921.7151 - mae: 921.7151\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.1827 - mae: 1165.1827\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 710.2880 - mae: 710.2880\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1566.9760 - mae: 1566.9760\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.8850 - mae: 599.8850\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 842.3273 - mae: 842.3273\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.5808 - mae: 594.5808\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1034.0206 - mae: 1034.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1897.0597 - mae: 1897.0597\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2766.8320 - mae: 2766.8320\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 569.8053 - mae: 569.8053\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.1627 - mae: 599.1627\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 696.6347 - mae: 696.6347\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.0875 - mae: 588.0875\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1183.5697 - mae: 1183.5697\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 860.4949 - mae: 860.4949\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.8687 - mae: 701.8687\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1064.9458 - mae: 1064.9458\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 567.0703 - mae: 567.0703\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.2266 - mae: 597.2266\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 604.3671 - mae: 604.3671\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.1885 - mae: 594.1885\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 763.7223 - mae: 763.7223\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 795.6566 - mae: 795.6566\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1570.6376 - mae: 1570.6376\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2235.1682 - mae: 2235.1682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd5984f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(batch_size=1, input_shape=(1), name=\"InputLayer\"),\n",
    "    tf.keras.layers.Dense(10, name=\"HiddenLayer\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_2.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "model_2.fit(xtr, ytr, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Mse: 292507.375 | Mae: 336.7899169921875\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_2 = model_2.predict(xte)\n",
    "\n",
    "see(y_preds_2, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "Equals to model 1, but with 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1826.4309 - mae: 1826.4309\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1815.3768 - mae: 1815.3768\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1804.4382 - mae: 1804.4382\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1796.7949 - mae: 1796.7949\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1780.5513 - mae: 1780.5513\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1763.2102 - mae: 1763.2102\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1749.0326 - mae: 1749.0326\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1737.1427 - mae: 1737.1427\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1729.6921 - mae: 1729.6921\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1719.8347 - mae: 1719.8347\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1708.9958 - mae: 1708.9958\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1697.0376 - mae: 1697.0376\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1679.7261 - mae: 1679.7261\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1666.5156 - mae: 1666.5156\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1654.8596 - mae: 1654.8596\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1639.5762 - mae: 1639.5762\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1622.5930 - mae: 1622.5930\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1612.1777 - mae: 1612.1777\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1598.5608 - mae: 1598.5608\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1581.6548 - mae: 1581.6548\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1573.6387 - mae: 1573.6387\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1560.7933 - mae: 1560.7933\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1545.6035 - mae: 1545.6035\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1531.6267 - mae: 1531.6267\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1518.3712 - mae: 1518.3712\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1505.3466 - mae: 1505.3466\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1492.0837 - mae: 1492.0837\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1478.9574 - mae: 1478.9574\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1469.8738 - mae: 1469.8738\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1453.2184 - mae: 1453.2184\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1438.1874 - mae: 1438.1874\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1429.3966 - mae: 1429.3966\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1421.9269 - mae: 1421.9269\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1403.5316 - mae: 1403.5316\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1385.8230 - mae: 1385.8230\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1367.4403 - mae: 1367.4403\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1357.8744 - mae: 1357.8744\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1341.0841 - mae: 1341.0841\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1329.3013 - mae: 1329.3013\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1317.7715 - mae: 1317.7715\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1306.6426 - mae: 1306.6426\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1292.9906 - mae: 1292.9906\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1274.8694 - mae: 1274.8694\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1266.3087 - mae: 1266.3087\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1258.8051 - mae: 1258.8051\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1247.2450 - mae: 1247.2450\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1235.1722 - mae: 1235.1722\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1222.0455 - mae: 1222.0455\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1212.9478 - mae: 1212.9478\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1195.7161 - mae: 1195.7161\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1177.2498 - mae: 1177.2498\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1165.3679 - mae: 1165.3679\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1157.9121 - mae: 1157.9121\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1140.0149 - mae: 1140.0149\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1123.0496 - mae: 1123.0496\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1105.4407 - mae: 1105.4407\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1090.3107 - mae: 1090.3107\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1078.0863 - mae: 1078.0863\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1059.9420 - mae: 1059.9420\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1050.5829 - mae: 1050.5829\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1040.2543 - mae: 1040.2543\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1021.6632 - mae: 1021.6632\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1005.6870 - mae: 1005.6870\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 997.0180 - mae: 997.0180\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 986.2400 - mae: 986.2400\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 976.2129 - mae: 976.2129\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 959.7241 - mae: 959.7241\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 942.3572 - mae: 942.3572\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 934.7939 - mae: 934.7939\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 921.2932 - mae: 921.2932\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 908.2378 - mae: 908.2378\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 901.5795 - mae: 901.5795\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 893.4252 - mae: 893.4252\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 876.0840 - mae: 876.0840\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 861.7178 - mae: 861.7178\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 843.6089 - mae: 843.6089\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 831.7204 - mae: 831.7204\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 814.4788 - mae: 814.4788\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 805.6436 - mae: 805.6436\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 795.7215 - mae: 795.7215\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 791.0927 - mae: 791.0927\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 778.2471 - mae: 778.2471\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 763.7402 - mae: 763.7402\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 750.1713 - mae: 750.1713\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 743.0460 - mae: 743.0460\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 741.2668 - mae: 741.2668\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 740.0448 - mae: 740.0448\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 736.8660 - mae: 736.8660\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 726.4778 - mae: 726.4778\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 719.2236 - mae: 719.2236\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 718.5413 - mae: 718.5413\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 711.2629 - mae: 711.2629\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 705.0186 - mae: 705.0186\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 704.3236 - mae: 704.3236\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 702.7917 - mae: 702.7917\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.0508 - mae: 701.0508\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.2601 - mae: 701.2601\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 701.7204 - mae: 701.7204\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 693.2158 - mae: 693.2158\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.7516 - mae: 685.7516\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 685.3978 - mae: 685.3978\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 679.1622 - mae: 679.1622\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 677.8302 - mae: 677.8302\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 672.3395 - mae: 672.3395\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 666.5579 - mae: 666.5579\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 660.0281 - mae: 660.0281\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.3240 - mae: 653.3240\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.7014 - mae: 653.7014\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 653.2452 - mae: 653.2452\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 647.5685 - mae: 647.5685\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 648.4724 - mae: 648.4724\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 643.2686 - mae: 643.2686\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 643.9183 - mae: 643.9183\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 643.1877 - mae: 643.1877\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 644.2806 - mae: 644.2806\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 644.9874 - mae: 644.9874\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 640.1509 - mae: 640.1509\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 641.3818 - mae: 641.3818\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 637.1581 - mae: 637.1581\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 638.1575 - mae: 638.1575\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 639.2968 - mae: 639.2968\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 634.5330 - mae: 634.5330\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 634.2207 - mae: 634.2207\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 635.0878 - mae: 635.0878\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 634.8641 - mae: 634.8641\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 631.0964 - mae: 631.0964\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 628.0972 - mae: 628.0972\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 629.2130 - mae: 629.2130\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 625.9385 - mae: 625.9385\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 622.4199 - mae: 622.4199\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 622.0364 - mae: 622.0364\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 618.7421 - mae: 618.7421\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 619.1914 - mae: 619.1914\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 619.7120 - mae: 619.7120\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 616.0205 - mae: 616.0205\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 616.3525 - mae: 616.3525\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 613.6409 - mae: 613.6409\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 611.2225 - mae: 611.2225\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 612.1623 - mae: 612.1623\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 612.3223 - mae: 612.3223\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 612.1450 - mae: 612.1450\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 611.9645 - mae: 611.9645\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 611.6392 - mae: 611.6392\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 609.4917 - mae: 609.4917\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 609.8892 - mae: 609.8892\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 610.8859 - mae: 610.8859\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 611.2292 - mae: 611.2292\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 608.6657 - mae: 608.6657\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.1769 - mae: 607.1769\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.2394 - mae: 607.2394\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.7432 - mae: 607.7432\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.8477 - mae: 607.8477\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 606.5282 - mae: 606.5282\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 607.1906 - mae: 607.1906\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 607.4770 - mae: 607.4770\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.9955 - mae: 605.9955\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 606.5739 - mae: 606.5739\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 607.0131 - mae: 607.0131\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.6935 - mae: 605.6935\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.3561 - mae: 606.3561\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.6450 - mae: 606.6450\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 605.4824 - mae: 605.4824\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 606.1029 - mae: 606.1029\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 604.6938 - mae: 604.6938\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 603.1875 - mae: 603.1875\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 603.1071 - mae: 603.1071\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.6080 - mae: 601.6080\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 602.4111 - mae: 602.4111\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.2443 - mae: 601.2443\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.7728 - mae: 601.7728\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 600.2088 - mae: 600.2088\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.0288 - mae: 601.0288\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 601.4673 - mae: 601.4673\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 599.9957 - mae: 599.9957\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 598.6210 - mae: 598.6210\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.4410 - mae: 599.4410\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.9078 - mae: 599.9078\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.8952 - mae: 599.8952\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 600.6967 - mae: 600.6967\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.3607 - mae: 599.3607\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 599.6777 - mae: 599.6777\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 600.3575 - mae: 600.3575\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 598.8505 - mae: 598.8505\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 599.5014 - mae: 599.5014\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 598.1240 - mae: 598.1240\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.6633 - mae: 596.6633\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.9503 - mae: 596.9503\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.6086 - mae: 595.6086\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.4751 - mae: 596.4751\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 597.2469 - mae: 597.2469\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 595.9633 - mae: 595.9633\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 596.6730 - mae: 596.6730\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 595.0125 - mae: 595.0125\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 593.6557 - mae: 593.6557\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 594.1972 - mae: 594.1972\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 594.4837 - mae: 594.4837\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 593.0698 - mae: 593.0698\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 593.6890 - mae: 593.6890\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0744 - mae: 592.0744\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.4909 - mae: 592.4909\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.7144 - mae: 592.7144\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.6370 - mae: 592.6370\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4518 - mae: 591.4518\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 591.5991 - mae: 591.5991\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9513 - mae: 591.9513\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.0866 - mae: 592.0866\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0986 - mae: 592.0986\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.6487 - mae: 590.6487\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.2404 - mae: 591.2404\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9973 - mae: 591.9973\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.4241 - mae: 592.4241\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.8630 - mae: 592.8630\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4553 - mae: 591.4553\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.1456 - mae: 590.1456\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.3095 - mae: 590.3095\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.2989 - mae: 590.2989\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.4938 - mae: 590.4938\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.9594 - mae: 588.9594\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.5629 - mae: 587.5629\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.9161 - mae: 587.9161\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.1127 - mae: 588.1127\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.8228 - mae: 588.8228\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.3043 - mae: 587.3043\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.7715 - mae: 587.7715\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.4604 - mae: 588.4604\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.6821 - mae: 588.6821\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.6033 - mae: 588.6033\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3401 - mae: 589.3401\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.2428 - mae: 589.2428\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.6104 - mae: 589.6104\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.1153 - mae: 590.1153\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.3151 - mae: 590.3151\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.1270 - mae: 591.1270\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4148 - mae: 591.4148\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.4802 - mae: 591.4802\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 592.0092 - mae: 592.0092\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.5182 - mae: 590.5182\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.8817 - mae: 590.8817\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 591.3186 - mae: 591.3186\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.9951 - mae: 591.9951\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.8550 - mae: 591.8550\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.5441 - mae: 590.5441\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.7087 - mae: 590.7087\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.4279 - mae: 591.4279\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 591.6808 - mae: 591.6808\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592.3016 - mae: 592.3016\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 590.9266 - mae: 590.9266\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.7641 - mae: 589.7641\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 590.3864 - mae: 590.3864\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.2023 - mae: 589.2023\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 589.3804 - mae: 589.3804\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.7336 - mae: 589.7336\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 589.8677 - mae: 589.8677\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.3649 - mae: 588.3649\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.9877 - mae: 586.9877\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.0283 - mae: 587.0283\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.9909 - mae: 586.9909\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.3352 - mae: 587.3352\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.9550 - mae: 587.9550\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4496 - mae: 586.4496\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4003 - mae: 586.4003\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.4794 - mae: 585.4794\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 585.9949 - mae: 585.9949\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.0495 - mae: 586.0495\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.3655 - mae: 586.3655\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.3515 - mae: 586.3515\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.4989 - mae: 586.4989\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.8454 - mae: 586.8454\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.7955 - mae: 586.7955\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.5361 - mae: 585.5361\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.7674 - mae: 585.7674\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.0890 - mae: 586.0890\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.2244 - mae: 586.2244\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 586.2988 - mae: 586.2988\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.0687 - mae: 587.0687\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.7626 - mae: 587.7626\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 588.1389 - mae: 588.1389\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 588.7886 - mae: 588.7886\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.2233 - mae: 587.2233\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.9383 - mae: 585.9383\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.6765 - mae: 586.6765\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.3227 - mae: 587.3227\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 587.2280 - mae: 587.2280\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 587.6081 - mae: 587.6081\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 586.3876 - mae: 586.3876\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 585.3907 - mae: 585.3907\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.9464 - mae: 584.9464\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.4423 - mae: 584.4423\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.9842 - mae: 583.9842\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5390 - mae: 583.5390\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5752 - mae: 583.5752\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1242 - mae: 583.1242\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4301 - mae: 583.4301\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.6171 - mae: 583.6171\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.8696 - mae: 583.8696\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.0178 - mae: 584.0178\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.1710 - mae: 584.1710\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.3937 - mae: 584.3937\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.5561 - mae: 584.5561\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.5609 - mae: 584.5609\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.0867 - mae: 584.0867\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.3979 - mae: 584.3979\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.6523 - mae: 584.6523\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 584.8256 - mae: 584.8256\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.8395 - mae: 584.8395\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.3938 - mae: 584.3938\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.9346 - mae: 583.9346\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 584.1290 - mae: 584.1290\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.6597 - mae: 583.6597\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2039 - mae: 583.2039\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7008 - mae: 582.7008\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7557 - mae: 582.7557\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.0690 - mae: 583.0690\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2142 - mae: 583.2142\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4628 - mae: 583.4628\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.9454 - mae: 582.9454\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.1551 - mae: 583.1551\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.4257 - mae: 583.4257\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.5399 - mae: 583.5399\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.7999 - mae: 583.7999\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2510 - mae: 583.2510\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7483 - mae: 582.7483\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.2554 - mae: 582.2554\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.8232 - mae: 581.8232\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0750 - mae: 582.0750\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2162 - mae: 582.2162\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.4127 - mae: 582.4127\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.4841 - mae: 582.4841\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.9490 - mae: 581.9490\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2248 - mae: 582.2248\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.4114 - mae: 582.4114\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.4919 - mae: 582.4919\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.9847 - mae: 581.9847\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.1620 - mae: 582.1620\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.2626 - mae: 582.2626\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.3130 - mae: 582.3130\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.5682 - mae: 582.5682\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.5511 - mae: 582.5511\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5898 - mae: 582.5898\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.6740 - mae: 582.6740\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.8244 - mae: 582.8244\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1351 - mae: 583.1351\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2140 - mae: 583.2140\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7871 - mae: 582.7871\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.0973 - mae: 583.0973\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5933 - mae: 582.5933\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.6193 - mae: 582.6193\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.8243 - mae: 582.8243\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.3929 - mae: 582.3929\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.6532 - mae: 582.6532\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7490 - mae: 582.7490\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.0261 - mae: 583.0261\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 583.0205 - mae: 583.0205\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.1463 - mae: 583.1463\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 583.2468 - mae: 583.2468\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.7894 - mae: 582.7894\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.3339 - mae: 582.3339\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.5852 - mae: 582.5852\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0219 - mae: 582.0219\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.0164 - mae: 582.0164\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1373 - mae: 582.1373\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1292 - mae: 582.1292\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.6201 - mae: 581.6201\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.9284 - mae: 581.9284\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1237 - mae: 582.1237\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 582.1399 - mae: 582.1399\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 582.1765 - mae: 582.1765\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 581.7180 - mae: 581.7180\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.7115 - mae: 581.7115\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 581.1503 - mae: 581.1503\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.6573 - mae: 580.6573\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.2112 - mae: 580.2112\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 580.2269 - mae: 580.2269\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 579.7603 - mae: 579.7603\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 579.2328 - mae: 579.2328\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.7835 - mae: 578.7835\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.9604 - mae: 578.9604\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.4328 - mae: 578.4328\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.4529 - mae: 578.4529\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.7214 - mae: 578.7214\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.7625 - mae: 578.7625\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1999 - mae: 578.1999\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7474 - mae: 577.7474\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.8856 - mae: 577.8856\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1741 - mae: 578.1741\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.3800 - mae: 578.3800\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.9214 - mae: 577.9214\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1312 - mae: 578.1312\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.5746 - mae: 577.5746\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7109 - mae: 577.7109\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.8140 - mae: 577.8140\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.8892 - mae: 577.8892\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.0350 - mae: 578.0350\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 578.1135 - mae: 578.1135\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.1143 - mae: 578.1143\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.3344 - mae: 578.3344\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7866 - mae: 577.7866\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.0532 - mae: 578.0532\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 578.2394 - mae: 578.2394\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.7468 - mae: 577.7468\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 577.9627 - mae: 577.9627\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.5062 - mae: 577.5062\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 577.0149 - mae: 577.0149\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.5225 - mae: 576.5225\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.5485 - mae: 576.5485\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.7583 - mae: 576.7583\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2043 - mae: 576.2043\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.3799 - mae: 576.3799\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.8873 - mae: 575.8873\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.4307 - mae: 575.4307\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.9482 - mae: 574.9482\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.1525 - mae: 575.1525\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.3397 - mae: 575.3397\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.4316 - mae: 575.4316\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7809 - mae: 575.7809\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.8145 - mae: 575.8145\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.1207 - mae: 576.1207\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.3036 - mae: 576.3036\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.6118 - mae: 576.6118\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.1654 - mae: 576.1654\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7224 - mae: 575.7224\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.9795 - mae: 575.9795\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.9841 - mae: 575.9841\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.0093 - mae: 576.0093\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2048 - mae: 576.2048\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7493 - mae: 575.7493\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0063 - mae: 576.0063\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.2017 - mae: 576.2017\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7471 - mae: 575.7471\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0159 - mae: 576.0159\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.2354 - mae: 576.2354\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.6900 - mae: 575.6900\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.8125 - mae: 575.8125\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.3401 - mae: 575.3401\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5196 - mae: 575.5196\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.6477 - mae: 575.6477\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7897 - mae: 575.7897\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7904 - mae: 575.7904\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 576.0071 - mae: 576.0071\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5286 - mae: 575.5286\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5991 - mae: 575.5991\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.0967 - mae: 575.0967\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5966 - mae: 574.5966\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.7010 - mae: 574.7010\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2533 - mae: 574.2533\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.6765 - mae: 574.6765\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5615 - mae: 574.5615\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9966 - mae: 574.9966\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9592 - mae: 574.9592\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5099 - mae: 575.5099\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.0167 - mae: 576.0167\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.7744 - mae: 575.7744\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 576.2180 - mae: 576.2180\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.9397 - mae: 575.9397\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.5928 - mae: 575.5928\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.5457 - mae: 575.5457\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.2789 - mae: 575.2789\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.0942 - mae: 575.0942\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7821 - mae: 574.7821\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.2740 - mae: 575.2740\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.7286 - mae: 575.7286\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 575.3907 - mae: 575.3907\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 575.1941 - mae: 575.1941\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9971 - mae: 574.9971\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7311 - mae: 574.7311\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6040 - mae: 574.6040\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4524 - mae: 574.4524\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.9716 - mae: 574.9716\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5383 - mae: 574.5383\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3650 - mae: 574.3650\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1693 - mae: 574.1693\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2520 - mae: 574.2520\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.5074 - mae: 574.5074\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6917 - mae: 574.6917\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.8866 - mae: 574.8866\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4290 - mae: 574.4290\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4460 - mae: 574.4460\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2506 - mae: 574.2506\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1930 - mae: 574.1930\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3293 - mae: 574.3293\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3347 - mae: 574.3347\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3177 - mae: 574.3177\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2595 - mae: 574.2595\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2125 - mae: 574.2125\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4901 - mae: 574.4901\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.6849 - mae: 574.6849\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.6893 - mae: 574.6893\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2422 - mae: 574.2422\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.4521 - mae: 574.4521\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2275 - mae: 574.2275\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2036 - mae: 574.2036\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2944 - mae: 574.2944\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.5218 - mae: 574.5218\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.7402 - mae: 574.7402\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.2195 - mae: 574.2195\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.3665 - mae: 574.3665\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.2777 - mae: 574.2777\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.1354 - mae: 574.1354\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 574.3242 - mae: 574.3242\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 574.4412 - mae: 574.4412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7fd706c70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "# Make model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model_3.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model_3.fit(xtr, ytr, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Mse: 306998.09375 | Mae: 406.56842041015625\n"
     ]
    }
   ],
   "source": [
    "# See how your model is going\n",
    "y_preds_3 = model_3.predict(xte)\n",
    "\n",
    "see(y_preds_3, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=306998.1>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_preds_3, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model1</td>\n",
       "      <td>402.489502</td>\n",
       "      <td>626321.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model2</td>\n",
       "      <td>336.789917</td>\n",
       "      <td>292507.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model3</td>\n",
       "      <td>406.568420</td>\n",
       "      <td>306998.09375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model         mae           mse\n",
       "0  Model1  402.489502  626321.68750\n",
       "1  Model2  336.789917  292507.37500\n",
       "2  Model3  406.568420  306998.09375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = [\n",
    "    [\"Model1\", mae(y_preds_1, yte).numpy(), mse(y_preds_1, yte).numpy()],\n",
    "    [\"Model2\", mae(y_preds_2, yte).numpy(), mse(y_preds_2, yte).numpy()],\n",
    "    [\"Model3\", mae(y_preds_3, yte).numpy(), mse(y_preds_3, yte).numpy()]\n",
    "]\n",
    "\n",
    "model_results = pd.DataFrame(models_results, columns=[\"model\", \"mae\", \"mse\"])\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer (Dense)         (1, 10)                   20        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 1)                    11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 2 was the better\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your main goal is to minimize the time between training sessions, because the more ou try different things and works in cicle, the more you discover the things that dont work, and the more you aproximate the better possible model, remember the machine learning people motto: experiment, experiment, experiment!\n",
    "\n",
    "This is the reason why you compare models! You try simple models first, see the best, try variatons of the best, take the best, and move on!\n",
    "\n",
    "Now we are gonna stop testing because this is a course, but in real life, you wold take model 2 and move on with the exprimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking your experiments (This is a very, very, good practice)\n",
    "\n",
    "We have tools for this:\n",
    "\n",
    "* TensorBoard\n",
    "* Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baf1db779f0cdc1ce48b1fe9bcd8ead02e6c1caf4dfdb394510f91c1920b3eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
